---
title: "Implementation - stationary use"
author: "Juan S Vargas"
date: "2023-06-16"
output: html_document
---

# Implementation for the moveSTIR paper

Here I will use simulated tracks. The base movement model is an Ohrstein Uhlenbeck process (Martinez-Garcia et al. 2020), i.e. home ranging behavior around a central attractor. I combine this with the social smoothing kernel convolution approach described by Scharf et al. [@Scharf2018]. This is similar to the method used in the examples in the original moveSTIR paper, but it has an additional social smoothing kernel which allows to account for animals moving closer to each other, or moving together. I will use the simple, independent tracks first, and then make changes to test different case studies.


## Independent movement

First we will test the framework for a simulated scenario where movement is independent across individuals. While there could be overlap in the resulting utilization distributions and points where the tracks cross each other, there should be no significant temporal correlation in the location histories.
``` {r libraries}
library(sp)
library(move)
library(adehabitatHR)
library(adehabitatLT)
library(tidyverse)
library(cowplot)
library(ctmm)
```

```{r sim mov}
set.seed(1)
nind = 6
p.tau = 50# tau^-1 accounts for the average home range crossing rate (time^-1). tau^-1 is the rate in 1/time at which an individual returns to its home range center following an excursion
p.g = 0.1 # scalar that modulates the random noise. Sets the size of the home range, has units (Area/time)
p.lambdas = matrix(rpois(nind*2, 1/p.g), ncol = 2)# home range centers
p.x0 = p.lambdas+matrix(rnorm(nind*2), ncol = 2) # initial positions
# p.phi = 0.01 # trajectory smoothing parameter
nsteps = 1000

xs = replicate(nind, numeric(nsteps))
ys = replicate(nind, numeric(nsteps))

for (s in seq_len(nind)) {
  x <- y <- numeric(nsteps)
  x[1] <- mux <- p.x0[s,1]
  y[1] <- muy <- p.x0[s,2]
  xnoise = rnorm(nsteps)
  ynoise = rnorm(nsteps)
  # take successive steps
  for(i in seq_len(nsteps-1)) {
    x[i+1] = x[i]-1/p.tau*(x[i]-p.lambdas[s,1])+sqrt(p.g)*xnoise[i]
    y[i+1] = y[i]-1/p.tau*(y[i]-p.lambdas[s,2])+sqrt(p.g)*ynoise[i]
  }
  xs[,s] = x
  ys[,s] = y
}
```

```{r plot tracks}
# Plot
# palette
pal = hcl.colors(nind, "Set 2")
plot(xs,ys,type = "n", asp=1, las = 1, cex.lab = 1.2, cex.axis = 1.2)
sapply(seq_len(nind), \(x) lines(xs[,x],ys[,x],col = hcl.colors(nind, "Set 2")[x]))
points(p.lambdas, bg = pal, pch  = 24)
points(p.x0, bg = pal, pch = 21)
legend("bottomright", legend = 1:nind, col = pal, lty = 1, cex = 0.8)
```

To calculate the FOI between pairs of individuals we first need to determine their area of overlap. We determine the areas of probable contact using the conditional distribution of encounters (Noonan et al. 2021). The instantaneous encounter rate is calculated as

$$
\tilde\varepsilon_{ij}(t)=\gamma_{ij}\int dr_{ij}(t)\Phi(r_{ij}(t))p(r_{ij}(t))
$$
This is a product of the absolute distance between the individuals $r_{ij}(t)$, a contact function $\Phi$ and the probability density of the distance $p$. For stationary distributions and uncorrelated movement, this boils down to the normalized product of the individual probabilities from their respective utilization distributions:

$$
CDE_{ij}(r)=\frac{p_i(\mathbf r)p_j(\mathbf r)}{\iint d^2\mathbf{r'}p_i(\mathbf{r'})p_j(\mathbf{r'})}
$$

We build the UDs using autocorrelated kernel density estimation (Fleming et al. 2015), estimate the pairwise CDEs, and take the 95% polygon as the area in which to create the detection histories and calculate their correlation. The ctmm, akde and CDE methos are included in the `ctmm` package. 

```{r CDE-ctmm}
# create move objects
moveobjs <- lapply(seq_len(nind), \(c) move(x = xs[,c],y = ys[,c],time = as.POSIXct(3600*seq(1:nsteps),origin = Sys.time()), animal = paste0("individual",c), proj = "+proj=tmerc"))

# convert to telemetry
telemetries <- lapply(moveobjs, as.telemetry)

# ctmm fit
GUESS <- lapply(telemetries, \(i) ctmm.guess(i, interactive = F))
FITS <- lapply(seq_along(telemetries), \(i) ctmm.fit(telemetries[[i]], GUESS[[i]]))
names(FITS) <- paste0("ind",seq_along(FITS))
# AKDE
UDS <- akde(telemetries, FITS)
# pairwise CDE
CDEs <- list()
for (i in seq_along(UDS)) {
  for (j in seq_along(UDS)) {
    if(i >= j) next
    u1 <- UDS[[i]]
    u2 <- UDS[[j]]
    CDEs[[paste(i,j,sep = "-")]] <- encounter(list(u1, u2))
  }
}
# 95% polygons
CDEpolys <- lapply(CDEs, SpatialPolygonsDataFrame.UD)
```

Here are some examples for pairwise CDEs.

```{r plotUD}
par(mfrow = c(2,3))
plot(telemetries[1:2], col = pal[1:2], UD = CDEs[1], error = FALSE, pch=16) # specified error to avoid something wrong here with the error in the data
plot(telemetries[c(1,3)], col = pal[c(1,3)], UD = CDEs[2], error = FALSE, pch=16)
plot(telemetries[c(2,3)], col = pal[c(2,3)], UD = CDEs[6], error = FALSE, pch=16)
plot(telemetries[c(1,6)], col = pal[c(1,6)], UD = CDEs[5], error = FALSE, pch=16)
plot(telemetries[c(4,5)], col = pal[c(4,5)], UD = CDEs[13], error = FALSE, pch=16)
plot(telemetries[c(5,6)], col = pal[c(5,6)], UD = CDEs[15], error = FALSE, pch=16)
```

An alternative approach is to use simple kernel density estimation, and take the intersection of the 95% kernels to create the overlap area. This does not account for higher probabilities of contact in areas of higher use, and the estimated area of overlap could be smaller, as shown below. From this example it seems that the edges of the polygon overlaps correspond (roughly) to the upper estimate of the 95% CDE polygon, not to the central estimate. 

```{r get-plot-kernels, fig.height=3}
# create the spatialPoints object with id column
sim_sppoint <- SpatialPointsDataFrame(coords = data.frame(x = as.numeric(xs), y = as.numeric(ys)), data = data.frame(id = rep(1:nind, each = nrow(xs))))

# get the UDs
kuds <- kernelUD(sim_sppoint)
# Get the 95% home range polygon
HRs <- lapply(kuds, getverticeshr)
# Get the pairwise polygon intersections

# Plot an example of a CDE and the corresponding polygon overlap from the Kernel dens est. method
plot(CDEs[[3]])
raster::intersect(HRs[[1]],HRs[[4]])|>plot(col = "red", add=T)
```

Once we have the area of overlap we can estimate the correlation across individuals. There are two ways to go about this: to use the cells of the CDE discretized raster, or to select random points within the polygon. In either case the process is to determine the detection history for pairs of individuals at a given location. This is a binary matrix that shows whether an individual was or was not inside a given cell $x$ at a time point $t$. 
Let's do the grid approach first. We take the grid produced by the pairwise CDEs. The cells produced can be rather small and the computation takes some time. This can be accelerated somewhat by doing the calculation only for overlapping cells. For large grids with small cells it may also be faster to loop through the cells (currently the correlation is calculated for _all_ cell pairs and then I take the diagonal so that only the correlation across individuals for the same cell are kept).
```{r corr-grid approach}
# get the rasters for the CDEs
CDErasters <- lapply(CDEs, raster, DF = "PDF")
# matrix of possible lags
lagmat <- outer(seq_len(nsteps), seq_len(nsteps), "-")
lags <- round(unique(lagmat[lower.tri(lagmat,diag = TRUE)]))
lags <- lags[-length(lags)]
# list to store correlation values for every pair, every cell, and every lag
gridcors <- list()

# Loop over lags and cells for every pair of individuals. This took almost 3 h. 
tictoc::tic("outer"); for (i in seq_along(CDErasters)) {
  rast <- CDErasters[[i]]
  indpair <- names(CDErasters)[i]
  # raster resolution and center coords
  yr <- yres(rast)
  xr <- xres(rast)
  gridcenters <- coordinates(rast)
  # individual IDs from the name of the rasters
  ind1 <- as.numeric(substr(indpair, 1,1))
  ind2 <- as.numeric(substr(indpair, 3,3))
  posindex1 <- abs(outer(gridcenters[,1],xs[,ind1],"-"))<=xr/2 & abs(outer(gridcenters[,2],ys[,ind1],"-"))<=yr/2
  posindex2 <- abs(outer(gridcenters[,1],xs[,ind2],"-"))<=xr/2 & abs(outer(gridcenters[,2],ys[,ind2],"-"))<=yr/2
  cormat <- matrix(0, nrow = length(lags), ncol = nrow(gridcenters))
  
  # loop over lags
  tictoc::tic(msg = "lag"); for (s in seq_along(lags)) {
    l <- lags[s]
    matindices <- which(lagmat==l, arr.ind = TRUE)
    h1 <- t(posindex1[,matindices[,1]])
    h2 <- t(posindex2[,matindices[,2]])
    ovlpcells <- which((colSums(h1)*colSums(h2))>0)
    # loop over cells
    if (length(ovlpcells)>0) {
      cormat[s,ovlpcells] <- diag(as.matrix(cor(h1[,ovlpcells],h2[,ovlpcells])))
      # for (cl in ovlpcells) cormat[s,cl] <- cor(h1[,cl],h2[,cl])
    }
  }; tictoc::toc()
  gridcors[[indpair]] <- cormat
}; tictoc::toc()

# The gridcors can be very large if the cells are small, but we need only keep the integral product
corvals <- sapply(gridcors, \(x) colSums(x*exp(-lags)))
saveRDS(gridcors, "../data/example_correlations.rds")
rm(gridcors)

# Plot the regular gridded approach
for (i in seq_along(CDErasters)) {
  # par(mfrow = c(1,2))
  corval <- corvals[[i]]
  indpair <- names(CDErasters)[i]

  # corvals <- ptcors[[i]][1,]
  ind1 <- as.numeric(substr(indpair, 1,1))
  ind2 <- as.numeric(substr(indpair, 3,3))
  corvalsscaled <- (corval+1)/2
  corcols <- rgb(colorRamp(hcl.colors(10, "Blue-Red"))(corvalsscaled), maxColorValue = 255)
  
  plot(xs[,c(ind1,ind2)],ys[,c(ind1,ind2)],type = "n", asp = 1, las = 1, main = "Gridded approach")
  image(SpatialPixelsDataFrame(coordinates(CDErasters[[i]]), data = data.frame(cor = corval)), add=T,col = hcl.colors(11,"Blue-Red", rev = TRUE), zlim = c(-1,1))
  lines(xs[,ind1],ys[,ind1],pch = 16, col = hcl.colors(nind, "Set 2",alpha = 0.5)[ind1])
  lines(xs[,ind2],ys[,ind2],pch = 16, col = hcl.colors(nind, "Set 2",alpha = 0.5)[ind2])
  
  # corvals <- ptgridcors[[i]]
  # plot(xs[,c(ind1,ind2)],ys[,c(ind1,ind2)],type = "n", asp = 1, las = 1, main = "Random point estimation")
  # image(SpatialPixelsDataFrame(SpatialPoints(makegrid(hrovlps[[i]], cellsize = cellside)), data = data.frame(value = corvals)), add=T,col = hcl.colors(11,"Blue-Red", rev = TRUE), zlim = c(-1,1))
  # lines(xs[,ind1],ys[,ind1],pch = 16, col = hcl.colors(nind, "Set 2",alpha = 0.5)[ind1])
  # lines(xs[,ind2],ys[,ind2],pch = 16, col = hcl.colors(nind, "Set 2",alpha = 0.5)[ind2])
  # legend("bottomleft", fill = hcl.colors(11, "Blue-Red"),legend = seq(1,-1,length.out = 11))
}
```


---
We multiply the UDs pairwise to get the probability $p_i(x)p_j(x)$. This is the first component of the equation. The figure below shows an example of the result; we get a matrix of the same size, but the highest values will be the areas of overlap between individuals.

```{r UD-prod, fig.height=3}
# Calculate the per-cell product of expected values
udprod <- function(k1, k2) {k1@data*k2@data}

# Plot one example
plot(SpatialPixelsDataFrame(coordinates(kuds[[1]]), 
                            data = data.frame(udprod(kuds[[1]],kuds[[2]]))))
# Get all the products in a list
ind_combs <- expand.grid(ind2 = seq_along(kuds), ind1 = seq_along(kuds))
ind_combs <- ind_combs[ind_combs$ind1!=ind_combs$ind2,]
UDprods <- apply(ind_combs, 1, \(x) udprod(kuds[[x[2]]],kuds[[x[1]]]), simplify = FALSE)
```
For the remaining components, i.e. the standard deviation and the correlation, we need the location history for every individual. The location history is a $T$ by $X$ binary matrix, with $T$ the number of discrete time steps and $X$ the number of sites, that shows in which cell the individual was at every time point. We do this finding which grid cell center is closest for every spatial point.

```{r loc-hist}
# Next we need to determine the location histories. The location history is a matrix with time in rows, locations (grid cells) in columns. Matrix values represent whether the individual was (1) or was not (0) at that location at that time. So, we need to assign a cell to every location.

# Get the distance between the grid cell centers and every point in the tracking history. This creates a numeric matrix with points in rows, and grid cell centers in columns. 
point_grid_dists <- spDists(sim_tracks_sppoints, kuds[[1]])

# Create a binary matrix and split it by individual
loc_histories <-  apply(point_grid_dists, MARGIN = 1, \(x) x==min(x)) |> t() |>
  split(factor(sim_tracks_db$ind)) |> 
  lapply(matrix, ncol = ncol(point_grid_dists))

#### Important, the grid cells are not in order!!!

# Create a function to do this more formally (In prgress)
# get_lochist <- function(s, k) {
#   pt_grid_dist <- spDists(s,k)
#   l <- apply(pt_grid_dist, 1, \(x) x == min(x))
#   return(l)
# }
```
The location histories are iteratively resampled, to select times in the history of $i$ and match them with times in the history of $j$ $s$ time units before. Once we have these subsets of the location histories, we calculate the covariance across matching matrix columns for two different individuals. Another way is to divide the covariance, expressing it as the product of the per-cell standard deviation as $\sigma=\sqrt{\hat p(1-\hat p)}$, where $\hat p$ is the estimated probability for a binomial process, and the correlation across the same cells for two individuals. It would seem there is no gain in speed in calculating the correlation as opposed to the covariance.

```{r covariance}
# We need to integrate the product of the covariance between the presence of i at x at time t, and the presence of j at x at time u = t-s, across all lags s. This is then multiplied by e^(-mu*s)
get_cov <- function(lh) {
  # matrix of combinations. A t*t matrix of difference in time. This is used to
  # find the row-col combinations corresponding to a given lag
  lag_mat <- round(outer(sim_tracks[[1]]$time, sim_tracks[[1]]$time, "-"),5)
  lags <- unique(lag_mat[lower.tri(lag_mat,diag = TRUE)])
  lags <- lags[-length(lags)] # remove final value that would have only one possible combination
  
  # For every lag s, find the rows in host 1 and host 2 corresponding to times t
  # and t-s, calculate the covariance
  cell_covs <- replicate(n = nrow(ind_combs), 
                         expr = matrix(0, nrow = length(lags), 
                                       ncol = ncol(loc_histories[[1]])),
                         simplify = FALSE)
  
  for (r in 1:nrow(ind_combs)) {
    i <- ind_combs[r,2]
    j <- ind_combs[r,1]
    covmat <- cell_covs[[r]]
    for (s in seq_along(lags)) {
      l <- lags[s]
      # find position where those lags occur
      indices <- which(lag_mat==l, arr.ind = T)
      # subset host position matrices with indices
      h1 <- lh[[i]][indices[,1],]
      h2 <- lh[[j]][indices[,2],]
      ovlpcells <- which((colSums(h1)*colSums(h2))>0)
      if(length(ovlpcells)==0) next
      if (length(ovlpcells)>0) {
        h1sub <- h1[,ovlpcells]
        h2sub <- h2[,ovlpcells]
        covmat[s,ovlpcells] <- diag(as.matrix(cov(h1sub,h2sub)))# only the diagonal as we care only about same cells
      }
    }
    cell_covs[[r]] <- covmat
  }
  return(cell_covs)
}

cell_covs <- get_cov(loc_histories)
# multiply by the decay, and sum across 
cell_cov_int <- lapply(cell_covs, "*", exp(-nu*lags)) |> lapply(colSums)
```
We obtain a matrix with cells in rows, and combinations of individuals in columns. For every column we need to add the product of the UDs at that cell, and then scale by the epidemiological parameters to obtain the cell FOI.

```{r foi}
calculate_cell_foi <- function(ud, ci) {
  # ud are the products of the utilization distributions, cv is the list of integrated cell-specific covariance multiplied by the exponential decay
  UDmu <- lapply(ud, "*", 1/nu)
  compsum <- mapply("+", ci, UDmu,USE.NAMES = F) # add the UD product and the integrated covariance term
  cell_foi <- sapply(compsum, "*", beta*lam) # multiply by the epidemiological parameters
  cell_foi <- replace(cell_foi, cell_foi<0, 0)  # substitute negative values for 0s
  return(cell_foi)
}

cell_foi_indep <- calculate_cell_foi(UDprods, cell_cov_int)
```

We obtain a matrix where each column is a combination of two individuals, and every row is a cell in the landscape. The matrix values are the estimated FOI experienced by individual 1 from individual 2. By adding across the columns we can estimate the total FOI for that pair of individuals. From this matrix we can also calculate the total FOI that an individual experiences from all other individuals, either at a specific location or across the whole landscape.

```{r tracks-gg}
sim_tracks_db %>% ggplot()+geom_path(aes(x,y,color = factor(ind)), size=1)+theme_void(base_size = 14)+coord_sf()+labs(color="Individual")+theme(legend.position = "left") -> gg.tracks
```
```{r pairwise-foi}
# total FOI from for every pair of individuals
data.frame(ind_combs, foi = colSums(cell_foi_indep)) |>
  ggplot()+
  geom_raster(aes(factor(ind1),factor(ind2, levels = 6:1),fill=foi))+
  theme_minimal(base_size = 14)+
  labs(fill = "FOI", y = "Acquiring individual", x = "Depositing individual")+
  scale_x_discrete(breaks = 1:6, position = "top",expand = c(0,0))+
  scale_y_discrete(breaks = 1:6, expand = c(0,0))+
  theme(aspect.ratio = 1, panel.grid = element_blank()) -> gg.pairfoi

cowplot::plot_grid(gg.tracks,gg.pairfoi)
```

We can see that individual 1 has hardly any overlap, and its FOI values are the lowest. The product of the UDs is symmetrical, but the difference in order of arrival at a given site creates differences due to the covariance term.

```{r ind-foi}
# total FOI experienced across from all hosts combined
tapply(colSums(cell_foi_indep), ind_combs$ind1, sum)
# total FOI contributed to all other hosts
tapply(colSums(cell_foi_indep), ind_combs$ind2, sum)
```
```{r plot-cellfoi}
# Plot one example
plot(SpatialPixelsDataFrame(coordinates(kuds[[1]]), 
                            data = data.frame(rowSums(cell_foi_indep))))
```
```{r st-dev}
# # We can calculate the sd from the estimated p_i. Can we?
# stdevs_est <- lapply(kuds, \(x) sqrt(as.matrix(x)*(1-as.matrix(x))))

# calculate standard deviation from the data. For a Bernoulli process, the sd is sqrt(p(1-p)), where p is the column mean for the binary location history matrix.
getcellSD <- function(h) sqrt(colMeans(h)*(1-colMeans(h)))
# apply(h, 2, \(x) sqrt(mean(x)*(1-mean(x))))
stdevs <- lapply(loc_histories, getcellSD)
```
```{r}
sapply(cell_covs, rowMeans) %>% as_tibble() %>% add_column(lag = lags) %>% 
  pivot_longer(cols = starts_with("v")) %>% 
  ggplot()+geom_point(aes(lag,value,color = name))
```

## Joint movement

Now we will do the same for a case where there is joint movement for two hosts, but the rest are moving independently.

```{r joint-mov}
## 1. Import data, calculate UDs
sim_tracks <- lapply(list.files("../data", "joint(.*).csv",full.names = TRUE), read.csv)
sim_tracks_db <- do.call(rbind, sim_tracks)[,2:3] |> cbind(ind = rep(seq_along(sim_tracks), sapply(sim_tracks,nrow))) 
# create the spatialPoints object with id column
sim_tracks_sppoints <- SpatialPointsDataFrame(coords = sim_tracks_db[,1:2], 
                                              data = data.frame(id = sim_tracks_db$ind))
# get the UDs with a common grid
kuds <- kernelUD(sim_tracks_sppoints, same4all = TRUE)
# Get the cell area, for FOI calculation
cell_area <- kuds[[1]]@grid@cellsize |> prod()

## 2. UD product
ind_combs <- expand.grid(ind2 = seq_along(kuds), ind1 = seq_along(kuds))
ind_combs <- ind_combs[ind_combs$ind1!=ind_combs$ind2,]
UDprods <- apply(ind_combs, 1, \(x) udprod(kuds[[x[2]]],kuds[[x[1]]]), simplify = FALSE)

## 3. Location history
# Get the distance between the grid cell centers and every point in the tracking history. 
point_grid_dists <- spDists(sim_tracks_sppoints, kuds[[1]])
# Create a binary matrix and split it by individual
loc_histories <-  apply(point_grid_dists, MARGIN = 1, \(x) x==min(x)) |> t() |>
  split(factor(sim_tracks_db$ind)) |> 
  lapply(matrix, ncol = ncol(point_grid_dists))

## 4. Get the covariance
cell_covs_joint <- get_cov(loc_histories)

## 5. multiply by the decay, and sum across to integrate
cell_cov_int <- lapply(cell_covs_joint, "*", exp(-nu*lags)) |> lapply(colSums)

## 6. Combine the integrated covariance term and the  UD product, and scale by the epi parameters
cell_foi_joint <- calculate_cell_foi(UDprods, cell_cov_int)
```

```{r plot_joint_sim}
## 7. plots
data.frame(ind_combs, foi = colSums(cell_foi_joint))|>
  ggplot()+
  geom_raster(aes(factor(ind1),factor(ind2, levels = 6:1),fill=foi))+
  theme_minimal(base_size = 14)+
  labs(fill = "FOI", y = "Acquiring individual", x = "Depositing individual")+
  scale_x_discrete(breaks = 1:6, position = "top",expand = c(0,0))+
  scale_y_discrete(breaks = 1:6, expand = c(0,0))+
  theme(aspect.ratio = 1, panel.grid = element_blank()) -> gg.pairfoi

data.frame(ind_combs, foi = beta*lam*sapply(UDprods, sum)) |>
  ggplot()+
  geom_raster(aes(factor(ind1),factor(ind2, levels = 6:1),fill=foi))+
  theme_minimal(base_size = 14)+
  labs(fill = "FOI", y = "Acquiring individual", x = "Depositing individual")+
  scale_x_discrete(breaks = 1:6, position = "top",expand = c(0,0))+
  scale_y_discrete(breaks = 1:6, expand = c(0,0))+
  theme(aspect.ratio = 1, panel.grid = element_blank())-> gg.pairfoiindep

gg.tracks <- sim_tracks_db %>% ggplot()+geom_path(aes(x,y,color = factor(ind)), size=1)+theme_void(base_size = 14)+coord_sf()+labs(color="Individual")+theme(legend.position = "left")

plot_grid(gg.tracks,plot_grid(gg.pairfoi,gg.pairfoiindep,nrow=2, align = "v"))
```

There is a clear difference in FOI between the two individuals who are moving together, and the rest. The estimated FOI is at least twice as high for that pair as for the others. This difference is not due solely to the degree of overlap; while they do have the highest degree of overlap, they also overlap similarly with other individuals,

What happens if we do not incorporate the covariance term? This is, what if we assumed independent movement, and only used the product of the UDs, how much error would we be incurring?

```{r, fig.height=3}
tibble(ind_combs, foi_full = colSums(cell_foi_joint), foi_ud = beta*lam*sapply(UDprods,sum)) %>% mutate(udprop = (foi_full-foi_ud)/foi_full) %>% 
  ggplot()+geom_raster(aes(ind1,ind2, fill = udprop))+
  # scale_fill_gradient2(midpoint = 1)+
  theme_minimal()+
  theme(aspect.ratio = 1, panel.grid = element_blank())+
  labs(x = "Depositing individual", y = "Acquiring individual", fill = "Cov contribution")
```

In cases where there is little overlap the product of the UDs makes up the majority of the FOI. However when the individual tracks do overlap, the covariance term seemingly makes up the majority of the FOI.

Let's see how the covariance varies for the different combinations of individuals.

```{r}
# First let's see how the covariance term changes in response to s, the lag
sapply(cell_covs_joint, rowMeans) %>% as_tibble() %>% add_column(lag = lags) %>% 
  pivot_longer(cols = starts_with("v")) %>% 
  ggplot()+geom_point(aes(lag,value,color = name))+
  theme_classic(base_size = 14)+
  labs(x = "Lag s", y = "Covariance")
```

We see there is some periodic behavior with respect to the lag $s$ for a couple of the covariance series, the two combinations of the individuals that are moving together. The covariance is positive and high for small lags but decreases sharply. For the other series—with independent movement—there is no clear trend.

Let's take a look at the covariance term and how it's related to overlap.

```{r}
m1 <- kerneloverlap(sim_tracks_sppoints)
m2 <- diag(6)
m2[as.numeric(rownames(ind_combs))] <- sapply(cell_cov_int, sum)
plot(m1,m2)
```

```{r}
sapply(cell_covs_joint, rowMeans) %>% as_tibble() %>% add_column(lag = lags) %>% 
  pivot_longer(cols = starts_with("v")) %>% 
  ggplot()+geom_boxplot(aes(name,value))+
  theme_classic(base_size = 14)+
  labs(x = "Pair", y = "Covariance")
```

