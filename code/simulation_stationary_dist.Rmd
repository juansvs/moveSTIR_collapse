---
title: "Implementation - stationary use"
author: "Juan S Vargas"
date: "2023-06-16"
output: html_document
---


Here we show an example of how to  implement the probabilistic moveSTIR framework, using simulated movement tracks. The base movement model is an Ohrstein Uhlenbeck process (Martinez-Garcia et al. 2020) which represents the movement of animals with an established home range behavior around a central attractor. We combine this with the social smoothing kernel convolution approach described by Scharf et al. (2018), which allows to account for animals moving closer to each other, or travelling together. I will simulate a set of individuals, some pairs will be moving independently from each other, others move together constantly while others get close to each other temporarily and then drift apart. 
When movement is independent across individuals there could be spatial overlap in the resulting utilization distributions and points where the tracks cross each other, but there should be no significant temporal correlation in the location histories. In contrast, animals the move in association with each other will have temporal correlation in their movements, which will influence their pairwise FOIs.  

``` {r libraries, message = FALSE}
library(sp)
library(move)
library(tidyverse)
library(ctmm)
```

## Movement simulation

```{r sim mov}
set.seed(1)
nind = 6
p.tau = 50# tau^-1 accounts for the average home range crossing rate (time^-1). tau^-1 is the rate in 1/time at which an individual returns to its home range center following an excursion
p.g = 1 # scalar that modulates the random noise. Sets the size of the home range, has units (Area/time)
p.lambdas = matrix(rpois(nind*2, 100*p.g)-100*p.g, ncol = 2)# home range centers
p.x0 = p.lambdas # initial positions
# p.phi = 0.01 # trajectory smoothing parameter
nsteps = 24*60

xs = replicate(nind, numeric(nsteps))
ys = replicate(nind, numeric(nsteps))

for (s in seq_len(nind)) {
  x <- y <- numeric(nsteps)
  x[1] <- mux <- p.x0[s,1]
  y[1] <- muy <- p.x0[s,2]
  xnoise = rnorm(nsteps)
  ynoise = rnorm(nsteps)
  # take successive steps
  for(i in seq_len(nsteps-1)) {
    x[i+1] = x[i]-1/p.tau*(x[i]-p.lambdas[s,1])+sqrt(p.g)*xnoise[i]
    y[i+1] = y[i]-1/p.tau*(y[i]-p.lambdas[s,2])+sqrt(p.g)*ynoise[i]
  }
  xs[,s] = x
  ys[,s] = y
}
```

### Social smoothing

Once we have the tracks from the OU process, we apply a social filter. The social smoothing kernel proposed in Scharf et al. (2018) is
$$
h_{ij}^{(soc)}\equiv1_{\{\tau=\tau_{soc}\}}\frac{w_{ij}(\tau_{soc})}{|w_i.(\tau_{soc})|}\\
|w_i.(\tau_{soc})|\equiv\sum_{j=1}^pw_{ij}(\tau_{soc})
$$
The position is obtained as:

$$
\mu_1^{(soc)}(\tau_{soc})\equiv\sum_{j=1}^p\int_\mathcal{T} h_{ij}^{(soc)}(\tau_{soc},\tau)\mu_j(\tau)d\tau
$$

Simply, the x or y position is the weighted average of the positions of the individual and the other individuals, with the weights the social network edge values at that moment. In this example, we create a convolution kernel where one pair of individuals moves together, one gets close and then drifts away, and the other pairs are independent from each other. 

```{r social convolution}
# Social network edge strengths. This can be time dependent, e.g. a list of length nsteps where each element is a matrix of edge weights
wstable <- 1
wdyn <- sin(pi*seq_len(nsteps)/nsteps) # sequence that increases and decrases, between 0 and 1. Can be changed.
W <- replicate(nsteps, diag(nrow = nind, ncol = nind))
W[1,2,] <- wstable # pair that will travel together
W[3,4,] <- wdyn # pair that will get close and then drift apart
# make symmetric
W <- apply(W, 3, \(x) x*upper.tri(x, diag = T)+t(x*upper.tri(x)), simplify = FALSE)

# convolution kernel hij(tau) is the weights matrix, divided by the row sums
h_soc <- lapply(W, \(x) x/rowSums(x))
# create empty matrices with the same dimensions as the position matrices
xsoc <- matrix(nrow = nrow(xs), ncol = ncol(xs))
ysoc <- matrix(nrow = nrow(ys), ncol = ncol(ys))
# fill the array using dot product of the step*ind x and y matrices, multiplied by the rows of h_soc
for (t in 1:nsteps) {
    xsoc[t,] <- h_soc[[t]]%*%xs[t,]
    ysoc[t,] <- h_soc[[t]]%*%ys[t,]
}
```

```{r plot tracks, fig.cap="Simulated tracks created using a Urstein-Ohlenbeck process modifed with a social smoothing convolution process"}
# Plot
# palette
pal = hcl.colors(nind, "Set 2")
par(mfrow = c(1,2))
plot(c(xs,xsoc),c(ys,ysoc), las = 1, asp = 1, type = 'n', cex.lab = 1.2, cex.axis = 1.2, xlab = "x", ylab = "y", main = "OU process")
sapply(seq_len(nind), \(x) lines(xs[,x],ys[,x],col = hcl.colors(nind, "Set 2")[x]))
points(p.lambdas, bg = pal, pch  = 24)
plot(c(xs,xsoc),c(ys,ysoc), las = 1, asp = 1, type = 'n', cex.lab = 1.2, cex.axis = 1.2, xlab = "x", ylab = "y", main = "OU with social convolution")
sapply(seq_len(nind), \(x) lines(xsoc[,x],ysoc[,x],col = hcl.colors(nind, "Set 2")[x]))
points(p.lambdas, bg = pal, pch  = 24)

# points(p.x0, bg = pal, pch = 21)
legend("bottomright", legend = 1:nind, col = pal, lty = 1, cex = 0.5)
```

The first term we need to calculate in the pMoveSTIR equation is the product between the probabilities of use of the same location by both individuals. This represents the spatial overlap, and is related to the probability of encounter (as described by Noonan et al. 2021). To calculate this, we first need to obtain the utilization distributions (UDs) for all animals.
We fit continuous time movement models to the trajectories of all individuals, and use autocorrelated kernel density estimation to obtain the UDs (Fleming et al. 2015). The ctmm and akde methods are included in the `ctmm` package. This creates a discrete grid for every individual, the values of which are the mean probability density values within each cell. For the discrete UD product we need the probability mass function, i.e. the total probability of being in a given *area*, so we need to scale the UD values multiplying by the grid cell area first. First we use the default grid resolution generated by the akde method, but we also later specify a grid defined by the threshold distance for considering potential transmission.

```{r ctmm UDs, message=FALSE}
# create move objects
moveobjs <- lapply(seq_len(nind), \(c) move(x = xsoc[,c],y = ysoc[,c],time = as.POSIXct(3600*seq_len(nsteps),origin = Sys.time()), animal = paste0("ind",c), proj = "+proj=tmerc"))

# convert to telemetry
telemetries <- lapply(moveobjs, as.telemetry)

# ctmm fit
GUESS <- lapply(telemetries, \(i) ctmm.guess(i, interactive = F))
FITS <- lapply(seq_along(telemetries), \(i) ctmm.fit(telemetries[[i]], GUESS[[i]]))
names(FITS) <- paste0("ind",seq_along(FITS))
# AKDE
UDS <- akde(telemetries, FITS)

```


## UD and standard deviation product

Once we have the individual UDs, we multiply them pairwise to get the probability $p_i(x)p_j(x)$. We calculate the standard deviation components also from the UDs. The per-cell standard deviation is $\sigma=\sqrt{\hat p(1-\hat p)}$, where $\hat p$ is the estimated probability for a binomial process (i.e. the UD PMF). Ideally, the probability of contact should be calculated at a scale relevant for epidemiological contact, which for large mammals is in the order of meters. We can, however, use the values estimated at a larger scale, provided we scale the density function to the same area as the correlation calculation. We obtain rasters where each cell has the value of the product, divided by the cell area. 

```{r UD-prod}
# transform UDs to raster class objects
UDrasts <- lapply(UDS, raster, DF = "PMF")
cellarea <- prod(res(UDrasts[[1]]))
# get total extent of UDs combined
globextent <- extent(do.call(merge,UDrasts))
# extend all rasters to have the same extent
UDrasts <- lapply(UDrasts, extend, y = globextent, value = 0)
# matrix of individual combinations
combs <- combn(length(UDS), 2)
# Create lists to store objects
UDprods <- UDsds <- list()
# Calculate product of probs, and sds, store as pairwise rasters with both
# combinations.
for (i in seq_len(ncol(combs))) {
  indpair <- names(CDErasters)[i]
  ind1 <- combs[1,i]
  ind2 <- combs[2,i]
  r1 <- UDrasts[[ind1]]
  r2 <- UDrasts[[ind2]]
  # product of probabilities, divided by area
  udprob <- r1*r2
  UDprods[[paste(ind1,ind2,sep = "-")]] <- UDprods[[paste(ind2,ind1,sep = "-")]] <- udprob/cellarea
  sdprob <- sqrt(r1*(1-r1))*sqrt(r2*(1-r2))
  UDsds[[paste(ind1,ind2,sep = "-")]] <- UDsds[[paste(ind2,ind1,sep = "-")]] <- sdprob/cellarea
}
```

Here are some examples for UD and SD products, with the corresponding locations of the individuals.

```{r plotUD}
par(mfrow = c(3,2))
plot(UDprods[[1]], main = paste("UD product", names(UDprods)[1]))
points(xsoc[,1],ysoc[,1], pch = '.', col = pal[1])
points(xsoc[,2],ysoc[,2], pch = '.', col = pal[2])
plot(UDsds[[1]], main = paste("SD product", names(UDprods)[1]))
points(xsoc[,1],ysoc[,1], pch = '.', col = pal[1])
points(xsoc[,2],ysoc[,2], pch = '.', col = pal[2])
plot(UDprods[[19]], main = paste("UD product", names(UDprods)[19]))
points(xsoc[,3],ysoc[,3], pch = '.', col = pal[3])
points(xsoc[,4],ysoc[,4], pch = '.', col = pal[4])
plot(UDsds[[19]], main = paste("SD product", names(UDprods)[19]))
points(xsoc[,3],ysoc[,3], pch = '.', col = pal[3])
points(xsoc[,4],ysoc[,4], pch = '.', col = pal[4])
plot(UDprods[[25]], main = paste("UD product", names(UDprods)[25]))
points(xsoc[,4],ysoc[,4], pch = '.', col = pal[4])
points(xsoc[,5],ysoc[,5], pch = '.', col = pal[5])
plot(UDsds[[25]], main = paste("SD product", names(UDprods)[25]))
points(xsoc[,4],ysoc[,4], pch = '.', col = pal[4])
points(xsoc[,5],ysoc[,5], pch = '.', col = pal[5])
```

## Correlation

Once we have the area of overlap we estimate the local temporal correlation across individuals. The correlation represents temporal similarity in space use, if animals are at the same location at the same time correlation will be positive, whereas if they visit the same locations but never at the same time correlation will be negative. Here we are estimating the cross-correlation, i.e. the correlation for different possible lags.
There are two ways to go about this calculation: to use the cells of the discretized raster, or to select random points within the area of overlap. In either case the process is to determine the detection history for pairs of individuals in a given area. This is a binary matrix that shows whether an individual was or was not inside the area $x$ at a time point $t$. 

### Grid approach

For the grid approach, we simply take the grid produced by the kernel density estimation. The problem with this is that there could be a mismatch between this scale and the threshold distance for epidemiological contact. This distance is usually small, in the order of a meters.

```{r corr-grid approach}
# list to store correlation values for every pair, every cell, and every lag
gridcors <- list()

for (i in seq_along(UDprods)) {
  rast <- UDprods[[i]]
  # keep only cells where the CDE is not 0. (For memory saving)
  indx <- Which(rast>0, cells = TRUE)
  # raster resolution and center coords
  yr <- yres(rast)
  xr <- xres(rast)
  gridcenters <- coordinates(rast)[indx,]
  # individual IDs from the name of the rasters
  indpair <- names(CDErasters)[i]
  ind1 <- as.numeric(substr(indpair, 1,1))
  ind2 <- as.numeric(substr(indpair, 3,3))
  # get position histories (i.e. which cell was each individual in at every time point)
  posindex1 <- abs(outer(xsoc[,ind1], gridcenters[,1],"-"))<=xr/2 & 
    abs(outer(ysoc[,ind1], gridcenters[,2],"-"))<=yr/2
  posindex2 <- abs(outer(xsoc[,ind2], gridcenters[,1],"-"))<=xr/2 & 
    abs(outer(ysoc[,ind2], gridcenters[,2],"-"))<=yr/2
  # keep only cells that both visited at some point
  ovlpcells <- which((colSums(posindex1)*colSums(posindex2))>0)
  if(length(ovlpcells)==0) {
    gridcors[[paste(ind1,ind2,sep = "-")]] <- NA
    gridcors[[paste(ind2,ind1,sep = "-")]] <- NA
    message("There are no overlap cells between ", ind1, " and ", ind2,", moving on to next pair")
    next
  }
  # keeping only cells with actual overlap of data, for memory saving
  indx <- indx[ovlpcells]
  posindex1 <- posindex1[,ovlpcells] 
  posindex2 <- posindex2[,ovlpcells]
 
  cormat_ab <- matrix(0,nrow = nrow(posindex1), ncol = ncol(posindex1))
  cormat_ba <- matrix(0,nrow = nrow(posindex1), ncol = ncol(posindex1))
  for (j in 1:ncol(posindex1)) { 
    a <- as.numeric(posindex1[,j])
    b <- as.numeric(posindex2[,j])
    maxlag <- nsteps-1
    xcorr <- ccf(a,b,lag.max = maxlag, plot = F)
    xcorr_vals <- as.numeric(xcorr$acf)
    cormat_ab[,j] <- rev(xcorr_vals[1:nsteps])
    cormat_ba[,j] <- xcorr_vals[nsteps:length(xcorr_vals)]
  }
  dimnames(cormat_ab) <- dimnames(cormat_ba) <- list(NULL, cell = indx)
  gridcors[[paste(ind1,ind2,sep = "-")]] <- cormat_ab
  gridcors[[paste(ind2,ind1,sep = "-")]] <- cormat_ba
}

saveRDS(gridcors, "../data/default_grid_correlations.rds")
# rm(gridcors)
# 
# # import back
# gridcors <- readRDS("../data/grid_correlations.rds")
```


### Random point approach

The other alternative is to sample randomly inside the area where encounters are likely, and estimate the correlation for every pair in an area around each sampled point. This approach allows to establish the contact distance based on the epidemiological dynamics, independently of the grid cell size. Here we use a square sampling area, but the same could be done with a circle. We sample within the 95% polygon of the utilization distribution product surface. 

```{r randompt-approach, message=FALSE}
# Get the 95% polygons from the UD product rasters
contour(UDprods[[1]],)
CDEpolys <- lapply(CDEs, SpatialPolygonsDataFrame.UD) |> lapply(polygons) |> 
  lapply(disaggregate)|>lapply("[",2)
# get the area of the polygons
CDE_ovlpareas <- sapply(CDEpolys,raster::area)

# set a threshold contact distance, calculate the number of cells with the
# corresponding area that would fit within the 95% CDE. Here we use square cells
cdist <- 0.01
samparea <- (cdist*2)^2
# thinning factor, to reduce the number of total points
tf <- 1/3
CDE_n_samplepts <- floor(CDE_ovlpareas/samparea*tf)

samplepts <- lapply(seq_along(CDEpolys), \(x) spsample(CDEpolys[[x]], n = CDE_n_samplepts[x], type = "random")) |> lapply(as.data.frame)
names(samplepts) <- names(CDEpolys)
ptcors <- list()

# Calculate the detections and correlations at every point
for (i in seq_along(samplepts)) {
  sppts <- samplepts[[i]]
  indpair <- names(samplepts)[i]
  ind1 <- as.numeric(substr(indpair, 1,1))
  ind2 <- as.numeric(substr(indpair, 3,3))
  
  # is point within threshold distance of center of cell (square sampling area)
  posindex1 <- abs(outer(xsoc[,ind1],coordinates(sppts)[,1],"-"))<=cdist & abs(outer(ysoc[,ind1],coordinates(sppts)[,2],"-"))<=cdist
  posindex2 <- abs(outer(xsoc[,ind2],coordinates(sppts)[,1],"-"))<=cdist & abs(outer(ysoc[,ind2],coordinates(sppts)[,2],"-"))<=cdist
  # matrix to store results
  cormat_ab <- cormat_ba <- matrix(0,nrow = nrow(posindex1), ncol = ncol(posindex1))
  # sampling cells where there is spatial overlap
  ovlpcells <- which((colSums(posindex1)*colSums(posindex2))>0)
  if(length(ovlpcells)==0) {
    ptcors[[paste(ind1,ind2,sep = "-")]] <- NA
    ptcors[[paste(ind2,ind1,sep = "-")]] <- NA
    message("There are no overlap cells between ", ind1, " and ", ind2,", moving on to next pair")
    next
  }
 for (j in ovlpcells) { 
    a <- as.numeric(posindex1[,j])
    b <- as.numeric(posindex2[,j])
    maxlag <- nsteps-1
    xcorr <- ccf(a,b,lag.max = maxlag, plot = F)
    xcorr_vals <- as.numeric(xcorr$acf)
    cormat_ab[,j] <- rev(xcorr_vals[1:nsteps])
    cormat_ba[,j] <- xcorr_vals[nsteps:length(xcorr_vals)]
  }
  cormat_ab <- as.matrix(cormat_ab[,ovlpcells], ncol = length(ovlpcells))
  cormat_ba <- as.matrix(cormat_ba[,ovlpcells], ncol = length(ovlpcells))
  dimnames(cormat_ab) <- dimnames(cormat_ba) <- list(NULL, cell = ovlpcells)
  ptcors[[paste(ind1,ind2,sep = "-")]] <- cormat_ab
  ptcors[[paste(ind2,ind1,sep = "-")]] <- cormat_ba
}

saveRDS(ptcors, "../data/randompoint_correlations.rds")
# rm(ptcors)
```


```{r plot approaches}
if(!exists("ptcors")) ptcors <- readRDS("../data/randompoint_correlations.rds")
if(!exists("gridcors")) gridcors <- readRDS("../data/grid_correlations.rds")
par(mfrow = c(1,3))
# parasite decay parameter. Values closer to 0 (slower decay) result in higher
# impact of correlation
nu = 1/96
lags <- seq_len(nsteps)-1
samplepts2 <- rep(samplepts, each = 2)
CDErasters2 <- rep(CDErasters, each = 2)
# get a range of values of correlation, for the color scale
ptcorrange <- lapply(ptcors, "*", exp(-nu*lags)) |> sapply(range) |> range(na.rm=T)
gridcorrange <- lapply(gridcors, "*", exp(-nu*lags)) |> sapply(range) |> range(na.rm=T)
globrange <- range(c(ptcorrange, gridcorrange))
for (i in seq_along(CDErasters2)) {
  indpair <- names(CDErasters2)[i]
  ind1 <- as.numeric(substr(indpair, 1,1))
  ind2 <- as.numeric(substr(indpair, 3,3))
  plot(xsoc[,c(ind1,ind2)],ysoc[,c(ind1,ind2)], type = "n", asp = 1, las = 1, main = "Tracks")
  lines(xsoc[,ind1],ysoc[,ind1], col = pal[ind1])
  lines(xsoc[,ind2],ysoc[,ind2], col = pal[ind2])
  
  plot(xsoc[,c(ind1,ind2)],ysoc[,c(ind1,ind2)], type = "n", asp = 1, las = 1, main = "Gridded approach")
  if(is.array(gridcors[[i]]))  {
    c1 <- colSums(gridcors[[i]]*exp(-nu*lags))
    # get raster and substitute values
    rast <- CDErasters2[[i]]
    values(rast) <- 0
    cells <- as.numeric(names(c1))
    values(rast)[cells] <- c1
    plot(rast, add = T, zlim = globrange)
  }

  plot(xsoc[,c(ind1,ind2)],ysoc[,c(ind1,ind2)],type = "n", asp = 1, las = 1, main = "Random point estimation")
  if(is.array(ptcors[[i]])) {
    c2 <- colSums(ptcors[[i]]*exp(-nu*lags))
    corvals <- numeric(length = nrow(samplepts2[[i]]))
    cells <- as.numeric(names(c2))
    corvals[cells] <- c2
    corvalsscaled <- (c2+max(abs(globrange)))/(2*max(abs(globrange)))
    corcols <- rgb(colorRamp(hcl.colors(11, "Blue-Red", rev = T))(corvalsscaled), maxColorValue = 255)
    points(samplepts2[[i]], col = corcols, pch = 16)
    legend("bottomright", fill = hcl.colors(5, "Blue-Red"),legend = format(seq(max(abs(globrange)),-max(abs(globrange)),length.out = 5),digits = 2))
  }
}
```

Animals that move together at the same time have the highest correlation terms, due to a high correlation at lag 0. This is true for pairs 1-2 and, to a lesser extent, 3-4. Other pairs that overlap substantially in space, like , have correlations close to 0. 

To compare both approaches, we integrate the values of the random point sampling inside each cell of the CDE grid. This may not be a fair comparison, since the contact area is much larger for the gridded approach than for the point approach. 
```{r integrate point estimates}
gridptcomp <- list()
for (i in seq_along(ptcors)) {
  if(!is.array(ptcors[[i]])) {
    gridptcomp[[i]] <- NA
  } else {
    corvals <- colSums(ptcors[[i]]*exp(-nu*lags))
    cells <- as.numeric(names(corvals))
    ptvals <- numeric(length = nrow(samplepts2[[i]]))
    ptvals[cells] <- corvals
    # get the cell that every point is in
    ptcells <- cellFromXY(CDErasters2[[i]], samplepts2[[i]])
    # data frame with the sample point coordinates, the correlation values, the
    # corresponding cell and its values
    cellmeancor <- tapply(ptvals, INDEX = ptcells, mean) # mean correlation for all sampled points within a cell
    cells <- as.numeric(names(cellmeancor))
    gridcor = Re(gridcors[[i]][cells]) # This real value should come much sooner.

    gridptcomp[[i]] <- data.frame(gridcell = cells, gridcor = gridcor, ptcor = cellmeancor)
  }
}

```

It would seem most cells in the grid have values close to 0. For these cells, the random sampling would be able to capture more nuance, although generally the values are lower with the point sampling approach. This makes sense given the smaller sampling area.



## FOI estimation

### Grid approach

For each cell, we multiply the product of the standard deviation by the cumulative correlation term. The result is added to the product of the UDs scaled by the epidemiological parameters to obtain the FOI. The UDs and SDs are stored as the mean value across the cell, so they need to be multiplied by the area. 

```{r grid foi calc}
foirasts <- list()
for (i in seq_along(gridcors)) {
  if (is.array(gridcors[[i]])) {
    # scale and integrate correlation at every cell
    corcells <- as.numeric(colnames(gridcors[[i]]))
    corvals <- numeric(length(CDErasters2[[i]]))
    corvals[corcells] <- colSums(gridcors[[i]]*exp(-nu*lags))
    corrast <- CDErasters2[[i]]
    values(corrast) <- corvals
    corrast <- extend(corrast, globextent, value=0)
    # this raster is smaller, I need to make it match with the cells for SD and
    # UD prods
    foi <- beta/cellarea*lam*(1/nu*UDprods[[i]]*cellarea+UDsds[[i]]*cellarea*corrast)
  } else {
    foi <- beta/cellarea*lam*(1/nu*UDprods[[i]]*cellarea)
  }
        # fill NAs with 0
    foi[is.na(foi) | foi<0] <- 0
    foirasts[[i]] <- foi
    plot(foi, las = 1, main = names(ptcors)[i])
}
names(foirasts) <- names(gridcors)
```
### Random point approach
In the random sampling approach, we calculate the FOI at the scale that we estimated the correlation by sampling the UD and SD products in the underlying cells. The UD products are calculated as probability density functions for each cell, so we need to multiply the products by the sampling area.

```{r pt foi calc}
ptfois <- list()
for (i in seq_along(samplepts2)) {
  udpdf <- extract(UDprods[[i]], samplepts2[[i]])
  sdprod <- extract(UDsds[[i]], samplepts2[[i]])
  corvals <- numeric(length = nrow(samplepts2[[i]]))
  if(is.array(ptcors[[i]])) {
    c2 <- colSums(ptcors[[i]]*exp(-nu*lags))
    cells <- as.numeric(names(c2))
    corvals[cells] <- c2
  } 
  # Calculate the FOI, the transmission is scaled by area, and the UD and SD
  # products are multiplied by the area. (So these cancel out??)
  ptfois[[i]] <- beta/samparea*lam*(udpdf*samparea/nu+sdprod*samparea*corvals)
}
```

Here is what the FOI looks like at all points for every pair, both from $i$ to $j$ and $j$ to $i$. (Saved as pdf externally)

```{r foi pt plot}
# Plot
pdf(file = "../docs/figures/ptSamplingFOI.pdf")
globrange <- c(0,max(sapply(ptfois, max)))
for (i in seq_along(CDErasters2)) {
  indpair <- names(CDErasters2)[i]
  ind1 <- as.numeric(substr(indpair, 1,1))
  ind2 <- as.numeric(substr(indpair, 3,3))
  plot(xsoc[,c(ind1,ind2)],ysoc[,c(ind1,ind2)], type = "n", asp = 1, las = 1, 
       main = paste(ind1, "<-", ind2), xlab = "x",ylab = "y")
  lines(xsoc[,ind1],ysoc[,ind1], col = pal[ind1])
  lines(xsoc[,ind2],ysoc[,ind2], col = pal[ind2])
  if(is.array(ptcors[[i]])) {
    posvals <- ptfois[[i]]*(ptfois[[i]]>=0)
    scaledvals <- posvals/diff(globrange)
    foicols <- rgb(colorRamp(colors = c("white","red"))(scaledvals), maxColorValue = 255)
    points(samplepts2[[i]], col = foicols, pch = ".")
    legend("bottomright", fill = colorRampPalette(c('white','red'))(5),legend = format(seq(globrange[1],globrange[2],length.out = 5),digits = 2, scientific = TRUE))
    }
}
dev.off()
```

## Smaller cells

A simple way to avoid scale mismatches is to set the scale of the discretized utilization distributions based on the threshold distance of the transmission process. That way all the calculations are performed at the same scale, which is the one relevant for transmission. Here I follow all the steps, starting with the estimation of the utilization distributions. The process is as follows:
  1. Create UDs, forcing a resolution equal to twice the threshold distance
  2. Transform UD objects to raster, extracting the per-cell probability mass, i.e. the probability density multiplied by the cell area
  3. Extend all rasters to a common grid
  4. Calculate the product of the UDs, and of the standard deviations. These are stored as rasters with the same grid. The values are divided by the cell area.
  5. Calculate the correlation in every grid cell. For this, I 
    a. Find which cell (of the large grid) the individual is in at every time point
    b. Find cells that both individuals visited at some point
    c. Create binary visit vectors for every cell in common
    d. Calculate the cross-correlation between corresponding vectors
    The results are stored as LxC matrices, where L is the number of lags, and C is the number of cells that both animals visited
  6. Calculate the FOI at every cell.
    a. Divide the UD products by $nu$, and multiply by the cell area
    b. Multiply the correlation values by $e^{-\nu \mathbf l}$, where $\mathbf l$ is the vector of lags. The unit of lags has to match the units of the decay rate. Integrate the results together.
    c. Multiply the integrated correlation term by the product of the SDs and by the cell area
    d. Add the result to the scaled UD product
    e. Multiply everything by $\beta\lambda/A$, where $A$ is the cell area. 

```{r epi size grid}
# create UDs with specified grid resolution
UDS_epi <- akde(telemetries, FITS, grid = list(dr = c(2*cdist, 2*cdist)))

### UD and SD products ###
UDepirasts <- lapply(UDS_epi, raster, DF = "PMF")
cellarea <- prod(res(UDepirasts[[1]]))

# extend all rasters to have the same extent. 
UDepirasts <- lapply(UDepirasts, extend, y = extent(do.call(merge,UDepirasts)), value = 0)
# Create lists to store objects
UDepiprods <- UDepisds <- list()
combs <- combn(length(UDS_epi), 2)
for (i in seq_len(ncol(combs))) {
  ind1 <- combs[1,i]
  ind2 <- combs[2,i]
  r1 <- UDepirasts[[ind1]]
  r2 <- UDepirasts[[ind2]]
  # product of probabilities, divided by area
  udprob <- r1*r2
  UDepiprods[[paste(ind1,ind2,sep = "-")]] <- UDepiprods[[paste(ind2,ind1,sep = "-")]] <- udprob/cellarea
  sdprob <- sqrt(r1*(1-r1))*sqrt(r2*(1-r2))
  UDepisds[[paste(ind1,ind2,sep = "-")]] <- UDepisds[[paste(ind2,ind1,sep = "-")]] <- sdprob/cellarea
}

### Correlation ###
# list to store correlation values
gridcors2 <- list()

for (i in seq_along(UDepiprods)) {
  r1 <- UDepiprods[[i]]

  # individual IDs from the name of the rasters
  indpair <- names(UDepiprods)[i]
  ind1 <- as.numeric(substr(indpair, 1,1))
  ind2 <- as.numeric(substr(indpair, 3,3))
  # get position histories (i.e. which cell was each individual in at every time
  # point). With large grids this represents a memory issue, because you have to
  # calculate a very large matrix of distances. I'll need to get just the actual
  # cell the individual is in, and create the vectors of the whole history at
  # the time of the correlation calculation
  pos1 <- cellFromXY(r1, xy = cbind(xsoc[,ind1],ysoc[,ind1]))
  pos2 <- cellFromXY(r1, xy = cbind(xsoc[,ind2],ysoc[,ind2]))

  # keep only cells that both visited at some point
  ovlpcells <- pos1[pos1 %in% pos2]
  if(length(ovlpcells)==0) {
    # Still fill in an item in the list, but write just NA. 
    gridcors2[[paste(ind1,ind2,sep = "-")]] <- NA
    gridcors2[[paste(ind2,ind1,sep = "-")]] <- NA
    message("There are no overlap cells between ", ind1, " and ", ind2,", moving on to next pair")
    next
  }

  maxlag <- nsteps-1
  cormat_ab <- cormat_ba <- matrix(0,nrow = nsteps, ncol = length(ovlpcells))
  for (j in seq_along(ovlpcells)) {
    cell <- ovlpcells[j]
    a <- b <- numeric(nsteps)
    a[match(cell, pos1)] <- b[match(cell, pos2)]<- 1
    xcorr <- ccf(a,b,lag.max = maxlag, plot = F)
    xcorr_vals <- as.numeric(xcorr$acf)
    cormat_ab[,j] <- rev(xcorr_vals[1:nsteps])
    cormat_ba[,j] <- xcorr_vals[nsteps:length(xcorr_vals)]
  }
  dimnames(cormat_ab) <- dimnames(cormat_ba) <- list(NULL, cell = ovlpcells)
  gridcors2[[paste(ind1,ind2,sep = "-")]] <- cormat_ab
  gridcors2[[paste(ind2,ind1,sep = "-")]] <- cormat_ba
}

### FOI ###
foirasts2 <- list()
pdf("../docs/figures/epigridFOI.pdf")
for (i in seq_along(gridcors2)) {
  if (is.array(gridcors2[[i]])) {
    # scale and integrate correlation at every cell
    corcells <- as.numeric(colnames(gridcors2[[i]]))
    corvals <- numeric(length(UDepiprods[[i]]))
    corvals[corcells] <- colSums(gridcors2[[i]]*exp(-nu*lags))
    corrast <- UDepiprods[[i]]
    values(corrast) <- corvals
    
    foi <- beta/cellarea*lam*(1/nu*UDepiprods[[i]]*cellarea+UDepisds[[i]]*cellarea*corrast)
  } else {
    foi <- beta/cellarea*lam*(1/nu*UDepiprods[[i]]*cellarea)
  }
  foi <- foi*(foi>=0)

  foirasts2[[i]] <- foi
  plot(foi, las = 1, main = names(gridcors2)[i])
}
dev.off()
names(foirasts2) <- names(gridcors2)
```
## FOI calculations

With the landscape pairwise FOI we can estimate the total FOI for every pair of individuals, the total FOI that an individual experiences from all other individuals, either at a specific location or across the whole landscape, as well as the total FOI across the landscape.

The FOI is much higher for the individuals that are interacting, which is to be expected given the higher overlap produced by the interaction. How much of this is actually contributed from the correlation/covariance terms, as opposed to the spatial overlap? The covariance term contributes less than 1% of the FOI (cell average), and only for the pair that travels together. This contribution is variable, it could be higher with a larger contact area or lower parasite decay rate, whereas the contribution from spatial overlap is stationary. 

### Effect of changing parasite decay rate
```{r foi v nu}
nus <- 1/2^(0:10)
covdf <- expand.grid(pair = names(gridcors2), nu = nus, totfoi = 0, covcontrib = 0)
for (x in seq_along(nus)) {
  nu = nus[x]
  rows = which(covdf$nu==nu)
  for (i in seq_along(gridcors2)) {
    if (is.array(gridcors2[[i]])) {
      # scale and integrate correlation at every cell
      corcells <- as.numeric(colnames(gridcors2[[i]]))
      corvals <- numeric(length(UDepiprods[[i]]))
      corvals[corcells] <- colSums(gridcors2[[i]]*exp(-nu*lags))
      corrast <- UDepiprods[[i]]
      values(corrast) <- corvals
      
      foi <- beta/cellarea*lam*(1/nu*UDepiprods[[i]]*cellarea+UDepisds[[i]]*cellarea*corrast)
    } else {
      foi <- beta/cellarea*lam*(1/nu*UDepiprods[[i]]*cellarea)
    }
    covdf$totfoi[rows[i]] <- cellStats(foi*(foi>=0), sum)
    covdf$covcontrib[rows[i]] <- cellStats(UDepisds[[i]]*corrast/(1/nu*UDepiprods[[i]]), mean)
  }
}
```
```{r foi v nu plot}
ggplot(covdf)+geom_line(aes(1/nu/24, totfoi,color = pair))+
  labs(x = expression(paste("Decay time ", 1/nu, " (Days)")),
       y = "Total FOI",
       color = "Pair")+
  theme_classic(base_size = 14)
```


```{r covcontrib v nu plot}
ggplot(covdf)+geom_line(aes(1/nu/24, covcontrib,color = pair))+
  labs(x = expression(paste("Decay time ", 1/nu, " (Days)")),
       y = "Covariance contribution (Cov/UD)",
       color = "Pair")+
  scale_y_log10()+
  geom_hline(yintercept = 1, linetype=2)+
  theme_classic(base_size = 14)
```

```{r pairwise foi plot}
covdf %>% separate(pair, into = c("Ind1", "Ind2")) %>% 
  ggplot()+geom_raster(aes(Ind1,Ind2,fill = totfoi))+
  facet_wrap(~round(1/nu/24,digits = 1))+
  scale_fill_gradient(low = "white", high = "red")+
  theme_classic()+
  labs(fill = "Total FOI")
  coord_equal()
```

### Effect of overlap on FOI
```{r}

```


Next we explore how the contact distance affects the estimations. With a longer contact distance, the likelihood of two individuals being in the same cell increases, so there should be more positive correlations and an overall greater contribution of the correlation term.

```{r contact fx}
# set a threshold contact distance, calculate the number of cells with the
# corresponding area that would fit within the 95% CDE. Here we use square cells
cdists <- seq(0.01,1,0.05)
cdist <- 0.01
samparea <- (cdist*2)^2
# thinning factor, to reduce the number of total points
tf <- 1/3
CDE_n_samplepts <- floor(CDE_ovlpareas/samparea*tf)

samplepts <- lapply(seq_along(CDEpolys), \(x) spsample(CDEpolys[[x]], n = CDE_n_samplepts[x], type = "random")) |> lapply(as.data.frame)
names(samplepts) <- names(CDEpolys)
ptcors <- list()

# Calculate the detections and correlations at every point
for (i in seq_along(samplepts)) {
  sppts <- samplepts[[i]]
  indpair <- names(samplepts)[i]
  ind1 <- as.numeric(substr(indpair, 1,1))
  ind2 <- as.numeric(substr(indpair, 3,3))
  
  # is point within threshold distance of center of cell (square sampling area)
  posindex1 <- abs(outer(xsoc[,ind1],coordinates(sppts)[,1],"-"))<=cdist & abs(outer(ysoc[,ind1],coordinates(sppts)[,2],"-"))<=cdist
  posindex2 <- abs(outer(xsoc[,ind2],coordinates(sppts)[,1],"-"))<=cdist & abs(outer(ysoc[,ind2],coordinates(sppts)[,2],"-"))<=cdist
  cormat_ab <- cormat_ba <- matrix(0,nrow = nrow(posindex1), ncol = ncol(posindex1))
  ovlpcells <- which((colSums(posindex1)*colSums(posindex2))>0)
  if(length(ovlpcells)==0) {
    ptcors[[paste(ind1,ind2,sep = "-")]] <- NA
    ptcors[[paste(ind2,ind1,sep = "-")]] <- NA
    next
  }
  for (j in ovlpcells) { 
    a <- posindex1[,j]
    b <- posindex2[,j]
    cormat_ab[,j] <- (convolve(a,b, type = "open")/sqrt(sum(a^2)*sum(b^2)))[length(a):(2*length(a)-1)]
    cormat_ba[,j] <- (convolve(b,a, type = "open")/sqrt(sum(a^2)*sum(b^2)))[length(b):(2*length(b)-1)]
  };toc()
  cormat_ab <- as.matrix(cormat_ab[,ovlpcells], ncol = length(ovlpcells))
  cormat_ba <- as.matrix(cormat_ba[,ovlpcells], ncol = length(ovlpcells))
  dimnames(cormat_ab) <- dimnames(cormat_ba) <- list(NULL, cell = ovlpcells)
  ptcors[[paste(ind1,ind2,sep = "-")]] <- cormat_ab
  ptcors[[paste(ind2,ind1,sep = "-")]] <- cormat_ba
}
# integration
gridptcomp <- list()
for (i in seq_along(ptcors)) {
  if(!is.array(ptcors[[i]])) {
    gridptcomp[[i]] <- NA
  } else {
    corvals <- colSums(Re(ptcors[[i]])*exp(-nu*lags))
    cells <- as.numeric(names(corvals))
    ptvals <- numeric(length = nrow(samplepts2[[i]]))
    ptvals[cells] <- corvals
    # get the cell that every point is in
    ptcells <- cellFromXY(CDErasters2[[i]], samplepts2[[i]])
    # data frame with the sample point coordinates, the correlation values, the
    # corresponding cell and its values
    cellmeancor <- tapply(ptvals, INDEX = ptcells, mean) # mean correlation for all sampled points within a cell
    cells <- as.numeric(names(cellmeancor))
    gridcor = Re(gridcors[[i]][cells]) # This real value should come much sooner.

    gridptcomp[[i]] <- data.frame(gridcell = cells, gridcor = gridcor, ptcor = cellmeancor)
  }
}

# foi
foirasts <- list()
# maybe best to create the global raster first, that way we would have a set of common cells for the remainder.
for (i in seq_along(ptcors)) {
  if (is.array(ptcors[[i]])) {
    # scale and integrate correlation at sampled points
    corvals <- colSums(Re(ptcors[[i]])*exp(-nu*lags))
    # get the indices of the points with values
    ptsswithvalues <- as.numeric(colnames(ptcors[[i]]))
    # find the corresponding cells in the global raster
    corcells <- cellFromXY(globrast, samplepts2[[i]][ptsswithvalues,])
    # mean correlation for all sampled points within a cell
    cellmeancor <- tapply(corvals, INDEX = corcells, mean) 
    # create global
    rcor <- globrast
    values(rcor) <- 0
    rcor[as.numeric(names(cellmeancor))] <- cellmeancor
    
    foi <- beta/nu*UDprods[[i]]+UDsds[[i]]*rcor

  } else {
    foi <- beta/nu*UDprods[[i]]
  }
        # fill NAs with 0
    foi[is.na(foi)] <- 0
    foirasts[[i]] <- foi
    plot(foi, las = 1, main = names(ptcors)[i])
}
names(foirasts) <- names(ptcors)
```

We obtain a matrix with cells in rows, and combinations of individuals in columns. For every column we need to add the product of the UDs at that cell, and then scale by the epidemiological parameters to obtain the cell FOI.

```{r foi}
calculate_cell_foi <- function(ud, ci) {
  # ud are the products of the utilization distributions, cv is the list of integrated cell-specific covariance multiplied by the exponential decay
  UDmu <- lapply(ud, "*", 1/nu)
  compsum <- mapply("+", ci, UDmu,USE.NAMES = F) # add the UD product and the integrated covariance term
  cell_foi <- sapply(compsum, "*", beta*lam) # multiply by the epidemiological parameters
  cell_foi <- replace(cell_foi, cell_foi<0, 0)  # substitute negative values for 0s
  return(cell_foi)
}

cell_foi_indep <- calculate_cell_foi(UDprods, cell_cov_int)
```





What happens if we do not incorporate the covariance term? This is, what if we assumed independent movement, and only used the product of the UDs, how much error would we be incurring?

```{r}
tibble(ind_combs, foi_full = colSums(cell_foi_joint), foi_ud = beta*lam*sapply(UDprods,sum)) %>% mutate(udprop = (foi_full-foi_ud)/foi_full) %>% 
  ggplot()+geom_raster(aes(ind1,ind2, fill = udprop))+
  # scale_fill_gradient2(midpoint = 1)+
  theme_minimal()+
  theme(aspect.ratio = 1, panel.grid = element_blank())+
  labs(x = "Depositing individual", y = "Acquiring individual", fill = "Cov contribution")
```

In cases where there is little overlap the product of the UDs makes up the majority of the FOI. However when the individual tracks do overlap, the covariance term seemingly makes up the majority of the FOI.

Let's see how the covariance varies for the different combinations of individuals.

```{r}
# First let's see how the covariance term changes in response to s, the lag
sapply(cell_covs_joint, rowMeans) %>% as_tibble() %>% add_column(lag = lags) %>% 
  pivot_longer(cols = starts_with("v")) %>% 
  ggplot()+geom_point(aes(lag,value,color = name))+
  theme_classic(base_size = 14)+
  labs(x = "Lag s", y = "Covariance")
```

We see there is some periodic behavior with respect to the lag $s$ for a couple of the covariance series, the two combinations of the individuals that are moving together. The covariance is positive and high for small lags but decreases sharply. For the other series—with independent movement—there is no clear trend.

Let's take a look at the covariance term and how it's related to overlap.

```{r}
m1 <- kerneloverlap(sim_tracks_sppoints)
m2 <- diag(6)
m2[as.numeric(rownames(ind_combs))] <- sapply(cell_cov_int, sum)
plot(m1,m2)
```

```{r}
sapply(cell_covs_joint, rowMeans) %>% as_tibble() %>% add_column(lag = lags) %>% 
  pivot_longer(cols = starts_with("v")) %>% 
  ggplot()+geom_boxplot(aes(name,value))+
  theme_classic(base_size = 14)+
  labs(x = "Pair", y = "Covariance")
```

