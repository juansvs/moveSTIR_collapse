---
title: "MoveSTIR collapse (study, explorations and thoughts)"
date: "2023-05-15"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The universal MoveSTIR framework

1.  **Upper right-hand corner**: *non-uniform space use*,
    *non-stationary time*

-   The upper right-hand corner of the box is the most general case
    where we allow transmission to vary at specific times and specific
    locations.

1.  **Lower right-hand corner**: *non-uniform space use*, *stationary
    time*

-   The lower right-hand corner of the box is where we assume
    stationarity in movement, but that stationary space use is not
    necessarily uniform.

1.  **Upper left-hand corner**: *uniform space use*, *non-stationary
    time*

-   In the upper left-hand corner, we assume space use is uniform
    (because, for example, we haven't observed space use, just contacts)
    and assume that contact is non-stationary (for example, there are
    seasonal fluctuations and pulses in contacts)

1.  **Lower left-hand corner**: *uniform space use*, *stationary time*

-   In the lower left-hand corner, we assume space use is uniform and
    movement is stationary. Given uncorrelated movements, we get back
    our standard FOI equation from mean field models.

The goal here is to understand how we infer
$E[h_{i \leftarrow j}(t, x)]$ -- the expected value of the force of
infection $i$ feels from $j$ at time $t$ in location $x$ with area
$A_x$. We want also want to understand how we can then infer this
quantity from different types of movement and contact data.

## Upper right-hand corner (general case)

We start with the original formulation for the force of infection, and
derive it to obtain the *expected* FOI: $$
\begin{aligned}
E[h_{i \leftarrow j}(x,t)] &= E\left[\int_{-\infty}^t \beta \lambda \delta_i(x, t) \delta_j(x, u) e^{-\nu(t - u)} du\right] \\
&= \int_{-\infty}^t \beta \lambda E[\delta_i(x, t) \delta_j(x, u)] e^{-\nu(t - u)} du \\
&= \beta \lambda \int_{-\infty}^t \left[p_i(x, t) p_j(x, u) + Cov(\delta_i(x, t), \delta_j(x, u))\right] e^{-\nu(t - u)} du \text{ (using } E[XY] = E[X]E[Y] + Cov(X, Y))\text{)}\\ 
&= \beta \lambda \left[\int_{-\infty}^t p_i(x, t) p_j(x, u) e^{-\nu(t - u)} du + \int_{-\infty}^t Cov(\delta_i(x, t), \delta_j(x, u)) e^{-\nu(t - u)} du\right] \\
\end{aligned}
$$ Scaling by the area of $x$ gives the following general equation for
the upper right-hand corner:

$$
E[h_{i\leftarrow j}(x,t)]=\frac{\beta'}{A_x} \lambda \left[\int_{-\infty}^t p_i(x, t) p_j(x, u) e^{-\nu(t - u)} du  + \int_{-\infty}^t Cov(\delta_i(x, t), \delta_j(x, u)) e^{-\nu(t - u)} du\right]
$$

where

-   $\beta'$: Acquisition rate (area units per time)
-   $\lambda$: Deposition rate ($t^{-1}$)
-   $\nu$: Pathogen decay rate in the environment ($t^{-1}$)
-   $\delta_i(x, t)$: An indicator random variable specifying whether
    host $i$ is in area $x$ at time $t$
-   $p_i(x, t)$: The marginal probability of host $i$ using habitat area
    $x$ at time $t$
-   $Cov(\delta_i(x, t), \delta_j(x, u))$: The covariance of host $i$
    and host $j$ both being in area $x$ at time $t$. Specifically, the
    spatio-temporal covariance of host $i$ and host $j$ being in
    "contact" at time $t$
    <!-- Is this not actually the covariance for the two individuals at the same location, but for different times? -->

This formulation is slightly different than our previous formulations
because $h\_{i \leftarrow j}(t, x)$ is also a *random variable*. This is
a more useful formulation when we are thinking about utilization
distributions because we want to think about where hosts are going to be
with some probability.

## Lower right-hand corner -- stationary spatial use

Now, if we assume a stationary distribution, the time indexes on
$p_i(x, t)$ and $p_j(x, u)$ are irrelevant---the logic here is that, by
definition, the mean of a stationary distribution is independent of time
so $p_i(x, t) = p_i(x)$ and $p_j(x, u) = p_j(x)$. Therefore, we can
write

$$
E[h_{i \leftarrow j}(t, x)] = \beta \lambda \left[p_i(x) p_j(x) (1 / \nu) + \int_{-\infty}^t Cov(\delta_i(x, t), \delta_j(x, u)) e^{-\nu(t - u)} du\right]
$$

where $\int_{-\infty}^t e^{-\nu(t - u)} du = \frac{1}{\nu}$.

In addition, given stationarity, $E[h_{i \leftarrow j}(t, x)]$ does not
depend on time so

$E[h_{i \leftarrow j}(t, x)] = E[h_{i \leftarrow j}(x)]$. Finally, given
stationarity, we know that $Cov(\delta_i(x, t), \delta_j(x, u))$ just
depends on the the time lag $t - u$ and not specific time stamps, so we
are really just focusing on $Cov(\delta_i(x), \delta_j(x) | t - u)$.
Thus, we can express the equation as

$$
E[h_{i \leftarrow j}(x)] = \beta \lambda \left[p_i(x) p_j(x) (1 / \nu) + \int_{0}^\infty Cov(\delta_i(x), \delta_j(x) | s) e^{-\nu s} ds\right]
$$

where $s = t - u$ (i.e., the lag) and we are integrating over infinite
lags.

This equation is pretty cool for a few reasons. First, we see how the
UD's of species $i$ and $j$ affect the average FOI. Second, we see that
temporal autocorrelation in movement can increase or decrease the
average FOI (some examples below show that this can be really important
for estimating pairwise FOI). This makes sense. If you have two
individuals moving randomly in an area vs. two individuals that are
always together in an area the FOI of the second pair of individuals
should be higher.

### Estimating from data

Requires estimating transient UDs and spatio-temporal contact covariance
functions. Transient UDs can be estimated with step-selection functions
or Fokker-Planck equations using GPS movement data. If $\delta_i(x)$ and
$\delta_j(x)$ are independent variables their covariance can be
calculated as:

$$
Cov(\delta_i(x),\delta_j(x))=\rho[\delta_i(x),\delta_j(x)]\sigma[\delta_i(x)]\sigma[\delta_j(x)]
$$

where $\rho(\delta_i(x),\delta_j(x))$ is the correlation between the
occurrences of $i$ and $j$ at $x$, and $\sigma(\delta_i(x))$ is the
standard deviation of the occurrences of $i$ at $x$. We obtain $$
E[h_{i\leftarrow j}(x)]=\beta\lambda\left[p_i(x)p_j(x)\frac{1}{\nu}+\int_0^\infty \rho[\delta_i(x),\delta_j(x)]\sigma[\delta_i(x)]\sigma[\delta_j(x)] e^{-\nu s}ds\right]
$$ If the correlation is constant through time, then we have $$
E[h_{i\leftarrow j}(x)]=\frac{\beta\lambda}{\nu}\left[p_i(x)p_j(x)+ \rho[\delta_i(x),\delta_j(x)]\sigma[\delta_i(x)]\sigma[\delta_j(x)] \right]
$$

```{r uniform space use, include=FALSE}
# Uniform space use
area <- 9
n <- 100 # total number of cells
# Probabilities of use for each cell
probs1 <- rep(1/n, n)
probs2 <- rep(1/n, n)

# Draw random number of locations at each location
points <- 1e4 # number of time points

host1 <- host2 <- matrix(0, nrow = points, ncol = n)
for (i in 1:points) {
  pos1 <- sample(1:n, size = 1, prob = probs1)
  pos2 <- sample(1:n, size = 1, prob = probs2)
  host1[i,pos1] <- 1
  host2[i,pos2] <- 1
}


# acquisition and deposition parameters
beta <- 1
lam <- 1
nu <- 1

# Calculate probability of use for each host and location
est_probs1 <- apply(host1, 2, mean)
est_probs2 <- apply(host2, 2, mean)

# Plot a landscape
g <- sqrt(n)
image(matrix(est_probs1, nrow = g))

# calculate the cell FOIs
cell_fois <- est_probs1*est_probs2*beta*n/area*lam/nu
# total FOI
total_foi <- beta/area*lam/nu
cat("Uniform space use","\nTotal FOI =", total_foi,"\nCell FOI =", sum(cell_fois))
```

```{r non-uniform space use, include=FALSE}
# Non-uniform space use
probs1 <- c(1,0.5,rep(0,n-2))
probs1 <- probs1/sum(probs1)
probs2 <- c(1,0.5,rep(0,n-2))
probs2 <- probs2/sum(probs2)
host1 <- host2 <- matrix(0, nrow = points, ncol = n)
for (i in 1:points) {
  pos1 <- sample(1:n, size = 1, prob = probs1)
  pos2 <- sample(1:n, size = 1, prob = probs2)
  host1[i,pos1] <- 1
  host2[i,pos2] <- 1
}
# estimate probs
est_probs1 <- apply(host1, 2, mean)
est_probs2 <- apply(host2, 2, mean)
# per-cell FOI 
cell_fois <- est_probs1*est_probs2*beta*n/area*lam/nu
total_foi <- beta/area*lam/nu

cat("Non uniform space use:","\nTotal FOI =",total_foi,"\nCell FOI =", sum(cell_fois))
```

```{r perfectly corr mov, include=FALSE}
# Correlated movements
probs1 <- runif(n)
probs1 <- probs1/sum(probs1)
probs2 <- runif(n)
probs2 <- probs2/sum(probs2)

host1 <- matrix(0, nrow = points, ncol = n)
for (i in 1:points) {
  pos1 <- sample(1:n, size = 1, prob = probs1)
  host1[i,pos1] <- 1
}
host2 <- host1
# estimate probs
est_probs1 <- apply(host1, 2, mean)
est_probs2 <- apply(host2, 2, mean)
# calculate correlations between hosts at each cell
cell_corr <- sapply(1:n, \(x) cor(host1[,x],host2[,x]))
cell_std1 <- apply(host1, 2, sd)
cell_std2 <- apply(host2, 2, sd)

# per-cell FOI 
cell_fois <- beta*n/area*lam/nu*(est_probs1*est_probs2+cell_corr*cell_std1*cell_std2)
total_foi <- beta/area*lam/nu

cat("Perfectly correlated movement:","\nTotal FOI =",total_foi,"\nCell FOI =", sum(cell_fois))
```

```{r partially corr mov, include=FALSE}
# partially correlated movement
probs1 <- runif(n)
probs1 <- probs1/sum(probs1)
probs2 <- runif(n)
probs2 <- probs2/sum(probs2)

host1 <- host2 <- matrix(0, nrow = points, ncol = n)
for (i in 1:points) {
  pos1 <- sample(1:n, size = 1, prob = probs1)
  host1[i,pos1] <- 1
}

for (i in 1:points) {
  if (runif(1)<0.8) {
      host2[i,] <- host1[i,]
  } else {
    pos2 <- sample(1:n, size = 1, prob = probs2)
    host2[i,pos2] <- 1
  }
}
# estimate probs
est_probs1 <- apply(host1, 2, mean)
est_probs2 <- apply(host2, 2, mean)
# calculate correlations between hosts at each cell
cell_corr <- sapply(1:n, \(x) cor(host1[,x],host2[,x]))
cell_std1 <- apply(host1, 2, sd)
cell_std2 <- apply(host2, 2, sd)
# per-cell FOI 
cell_fois <- beta*n/area*lam/nu*(est_probs1*est_probs2+cell_corr*cell_std1*cell_std2)
total_foi <- beta/area*lam/nu

cat("Partially correlated movement:","\nTotal FOI =",total_foi,"\nCell FOI =", sum(cell_fois))
```

We can use this expression that accounts for the entire history of
locations of $i$ and $j$ in $x$ if the correlation in movement is
constant. In practice we should be integrating across all possible
values of $s$, the possible time lags between the presence of $i$ and
$j$ at $x$.

To do this, we divide the entire history of occurrences at every x,
subsetting to take only times $s$ time units apart. We take the vectors
$\delta_i(t)$ and $\delta_j(t-s)$, and calculate the correlation and
standard deviations at every location $x$ for every time lag $s$. For
long time series there will be a large number of possible lags, so it
could make sense to set an upper threshold to relevant lags. A
systematic way to do this would be to link the threshold with the
parasite decay rate. For a decay rate of $\nu=1$, the initial value
would decrease by more than 99.99% after only nine days. We will set 10
days as a relevant threshold (this also significantly speeds things up
for the computation).

```{r cov integration}
# Calculate covariance as the product of correlation and st.dev. for every
# possible value of s 
# Possible lag values, from 0 (i and j together at the same
# time), to times-2
lags <- 0:10
# list to populate with covariance results
cov_s <- list()
# matrix of combinations. A t*t matrix of difference in time. This is used to
# find the row-col combinations corresponding to a given lag
lags_mat <- outer(1:points, 1:points, "-")

# For every lag s, find the rows in host 1 and host 2 corresponding to times t
# and t-s, calculate the correlation, st. dev., and their product
for (i in seq_along(lags)) {
  s <- lags[i]
  # find position where those lags occur
  indices <- which(lags_mat==s, arr.ind = T)
  # subset host position matrices with indices
  h1 <- host1[indices[,1],]
  h2 <- host2[indices[,2],]
    # Calculate correlation
    # estimate probs
    # est_probs1 <- apply(host1, 2, mean)
    # est_probs2 <- apply(host2, 2, mean)
    # calculate correlations, st. dev. at every x
    cell_corr <- sapply(1:n, \(x) cor(h1[,x],h2[,x]))
    cell_std1 <- apply(h1, 2, sd)
    cell_std2 <- apply(h2, 2, sd)
    # per-cell covariance
    cov_s[[i]] <- cell_corr*cell_std1*cell_std2
}
# Join together, multiply by exp(-nu*s), sum across values of s for each x
cov_x <- (do.call(rbind,cov_s)*exp(-nu*lags)) |> apply(MARGIN = 2, sum, na.rm = T)
cell_fois <- beta*n/area*lam*(est_probs1*est_probs2/nu+cov_x)
total_foi <- beta/area*lam/nu

cat("Partially correlated movement, full integration:","\nTotal FOI =",total_foi,"\nCell FOI =", sum(cell_fois))

```

As expected, we obtain virtually identical values as the previous
calculation, but this could vary if correlation is not constant through
time, for example if there is strong avoidance.

```{r strong avoidance}
# we will  create avoidance by establishing the position of i independently, but
# j will avoid locations where i has been in the previous 10 time
# steps.
probs1 <- runif(n)
probs1 <- probs1/sum(probs1)
probs2 <- runif(n)
probs2 <- probs2/sum(probs2)

host1 <- host2 <- matrix(0, nrow = points, ncol = n)
for (i in 1:points) {
  pos1 <- sample(1:n, size = 1, prob = probs1)
  host1[i,pos1] <- 1
}

for (i in 1:points) {
      # get previous 10 locations of host1
  if (i==1) {
    h1locs <- which(host1[i,]==1)
  } else {
    h1locs <- which(host1[i:max(i-10,1),]==1,arr.ind = TRUE)[,2]
  }
# decrease the probability at those locations by 80%
  p2 <- probs2
  p2[h1locs] <- p2[h1locs]*0.2
  pos2 <- sample(1:n, size = 1, prob = p2)
  host2[i,pos2] <- 1
}
# estimate probs
est_probs1 <- apply(host1, 2, mean)
est_probs2 <- apply(host2, 2, mean)
# calculate correlations between hosts at each cell
cell_corr <- sapply(1:n, \(x) cor(host1[,x],host2[,x]))
cell_std1 <- apply(host1, 2, sd)
cell_std2 <- apply(host2, 2, sd)
# per-cell FOI 
cell_fois1 <- beta*n/area*lam/nu*(est_probs1*est_probs2+cell_corr*cell_std1*cell_std2)
total_foi1 <- beta/area*lam/nu

lags <- 0:15
# list to populate with covariance results
cov_s <- list()
# matrix of combinations. A t*t matrix of difference in time. This is used to
# find the row-col combinations corresponding to a given lag
lags_mat <- outer(1:points, 1:points, "-")

# For every lag s, find the rows in host 1 and host 2 corresponding to times t
# and t-s, calculate the correlation, st. dev., and their product
for (i in seq_along(lags)) {
  s <- lags[i]
  # find position where those lags occur
  indices <- which(lags_mat==s, arr.ind = T)
  # subset host position matrices with indices
  h1 <- host1[indices[,1],]
  h2 <- host2[indices[,2],]
    # Calculate correlation
    # estimate probs
    # est_probs1 <- apply(host1, 2, mean)
    # est_probs2 <- apply(host2, 2, mean)
    # calculate correlations, st. dev. at every x
    cell_corr <- sapply(1:n, \(x) cor(h1[,x],h2[,x]))
    cell_std1 <- apply(h1, 2, sd)
    cell_std2 <- apply(h2, 2, sd)
    # per-cell covariance
    cov_s[[i]] <- cell_corr*cell_std1*cell_std2
}
# Join together, multiply by exp(-nu*s), sum across values of s for each x
cov_x <- (do.call(rbind,cov_s)*exp(-nu*lags)) |> apply(MARGIN = 2, sum, na.rm = T)

cell_fois2 <- beta*n/area*lam*(est_probs1*est_probs2/nu+cov_x)

cat("Partially correlated movement, full integration:","\nTotal FOI =",total_foi,"\nCell FOI approximation =", sum(cell_fois1, na.rm = T),"\nCell FOI integration =",sum(cell_fois2))
```

For local temporal avoidance, the estimated FOI is only slightly lower
than the expectation under the assumption of constant correlation. Both
values, however, are lower than the expectation that ignores the
covariance term.

### Implementation for the moveSTIR paper

Here I will use simulated tracks following the approach by Scharf et el.
[@Scharf2018]. This is similar to the method used in the examples in the
original moveSTIR paper, but it has an additional social smoothing
kernel which allows to account for animals moving closer to each other,
or moving together. I will use the simple, independent tracks first, and
then make changes to test different case studies.

#### Independent movement

First we will test the framework for a simulated scenario where movement
is independent across individuals. While there could be overlap in the
resulting utilization distributions and points where the tracks cross
each other, there should be no significant temporal correlation in the
location histories.

```{r import-plot-tracks}
library(sp)
library(adehabitatHR)
library(tidyverse)
library(cowplot)

# import the simulated data. The tracks are csv files generated using the movement_simulation.Rmd notebook
sim_tracks <- lapply(list.files("../data", "indep(.*).csv",full.names = TRUE), read.csv)

# join together
sim_tracks_db <- do.call(rbind, sim_tracks)[,2:3] |> cbind(ind = rep(seq_along(sim_tracks), sapply(sim_tracks,nrow))) 

# Create a figure to illustrate the example. This figure will have the tracks of multiple individuals, then their respective UDs, as well as the UD product.

plot(sim_tracks_db$x, sim_tracks_db$y, type = "n", asp = 1, axes = F, ann = F)
for (i in unique(sim_tracks_db$ind)) {
  lines(sim_tracks_db[sim_tracks_db$ind == i, ], col = hcl.colors(length(sim_tracks), palette = "Set 2")[i], lwd  = 1.2)
}
legend(x = "left",legend = 1:length(sim_tracks), col = hcl.colors(length(sim_tracks),palette = "Set 2"),border = F, lty = 1)
```

We then get the utilization distribution for every track. In this case I
am using simple kernel density estimation, i.e. I'm not using any
mechanistic movement model, but the same procedure would apply.

```{r get-plot-kernels, fig.height=3}
# create the spatialPoints object with id column
sim_tracks_sppoints <- SpatialPointsDataFrame(sim_tracks_db[,1:2], data = data.frame(id = sim_tracks_db$ind))
# get the UDs with a common grid
kuds <- kernelUD(sim_tracks_sppoints, same4all = TRUE)

# Get the cell area, for FOI calculation
cell_area <- kuds[[1]]@grid@cellsize |> prod()

sapply(kuds, plot)
```

We multiply these UDs pairwise to get the probability $p_i(x)p_j(x)$.
This is the first component of the equation. The figure below shows an
example of the result; we get a matrix of the same size, but the highest
values will be the areas of overlap between individuals.

```{r UD-prod, fig.height=3}
# Calculate the per-cell product of expected values
udprod <- function(k1, k2) {k1@data*k2@data}

# Plot one example
plot(SpatialPixelsDataFrame(coordinates(kuds[[1]]), 
                            data = data.frame(udprod(kuds[[1]],kuds[[2]]))))
# Get all the products in a list
ind_combs <- expand.grid(ind2 = seq_along(kuds), ind1 = seq_along(kuds))
ind_combs <- ind_combs[ind_combs$ind1!=ind_combs$ind2,]
UDprods <- apply(ind_combs, 1, \(x) udprod(kuds[[x[2]]],kuds[[x[1]]]), simplify = FALSE)
```

For the remaining components, i.e. the standard deviation and the
correlation, we need the location history for every individual. The
location history is a $T$ by $X$ binary matrix, with $T$ the number of
discrete time steps and $X$ the number of sites, that shows in which
cell the individual was at every time point. We do this finding which
grid cell center is closest for every spatial point.

```{r loc-hist}
# Next we need to determine the location histories. The location history is a matrix with time in rows, locations (grid cells) in columns. Matrix values represent whether the individual was (1) or was not (0) at that location at that time. So, we need to assign a cell to every location.

# Get the distance between the grid cell centers and every point in the tracking history. This creates a numeric matrix with points in rows, and grid cell centers in columns. 
point_grid_dists <- spDists(sim_tracks_sppoints, kuds[[1]])

# Create a binary matrix and split it by individual
loc_histories <-  apply(point_grid_dists, MARGIN = 1, \(x) x==min(x)) |> t() |>
  split(factor(sim_tracks_db$ind)) |> 
  lapply(matrix, ncol = ncol(point_grid_dists))

#### Important, the grid cells are not in order!!!

# Create a function to do this more formally (In prgress)
# get_lochist <- function(s, k) {
#   pt_grid_dist <- spDists(s,k)
#   l <- apply(pt_grid_dist, 1, \(x) x == min(x))
#   return(l)
# }
```

The location histories are iteratively resampled, to select times in the
history of $i$ and match them with times in the history of $j$ $s$ time
units before. Once we have these subsets of the location histories, we
calculate the covariance across matching matrix columns for two
different individuals. Another way is to divide the covariance,
expressing it as the product of the per-cell standard deviation as
$\sigma=\sqrt{\hat p(1-\hat p)}$, where $\hat p$ is the estimated
probability for a binomial process, and the correlation across the same
cells for two individuals. It would seem there is no gain in speed in
calculating the correlation as opposed to the covariance.

```{r covariance}
# We need to integrate the product of the covariance between the presence of i at x at time t, and the presence of j at x at time u = t-s, across all lags s. This is then multiplied by e^(-mu*s)
get_cov <- function(lh) {
  # matrix of combinations. A t*t matrix of difference in time. This is used to
  # find the row-col combinations corresponding to a given lag
  lag_mat <- round(outer(sim_tracks[[1]]$time, sim_tracks[[1]]$time, "-"),5)
  lags <- unique(lag_mat[lower.tri(lag_mat,diag = TRUE)])
  lags <- lags[-length(lags)] # remove final value that would have only one possible combination
  
  # For every lag s, find the rows in host 1 and host 2 corresponding to times t
  # and t-s, calculate the covariance
  cell_covs <- replicate(n = nrow(ind_combs), 
                         expr = matrix(0, nrow = length(lags), 
                                       ncol = ncol(loc_histories[[1]])),
                         simplify = FALSE)
  
  for (r in 1:nrow(ind_combs)) {
    i <- ind_combs[r,2]
    j <- ind_combs[r,1]
    covmat <- cell_covs[[r]]
    for (s in seq_along(lags)) {
      l <- lags[s]
      # find position where those lags occur
      indices <- which(lag_mat==l, arr.ind = T)
      # subset host position matrices with indices
      h1 <- lh[[i]][indices[,1],]
      h2 <- lh[[j]][indices[,2],]
      ovlpcells <- which((colSums(h1)*colSums(h2))>0)
      if(length(ovlpcells)==0) next
      if (length(ovlpcells)>0) {
        h1sub <- h1[,ovlpcells]
        h2sub <- h2[,ovlpcells]
        covmat[s,ovlpcells] <- diag(as.matrix(cov(h1sub,h2sub)))# only the diagonal as we care only about same cells
      }
    }
    cell_covs[[r]] <- covmat
  }
  return(cell_covs)
}

cell_covs <- get_cov(loc_histories)
# multiply by the decay, and sum across 
cell_cov_int <- lapply(cell_covs, "*", exp(-nu*lags)) |> lapply(colSums)
```

We obtain a matrix with cells in rows, and combinations of individuals
in columns. For every column we need to add the product of the UDs at
that cell, and then scale by the epidemiological parameters to obtain
the cell FOI.

```{r foi}
calculate_cell_foi <- function(ud, ci) {
  # ud are the products of the utilization distributions, cv is the list of integrated cell-specific covariance multiplied by the exponential decay
  UDmu <- lapply(ud, "*", 1/nu)
  compsum <- mapply("+", ci, UDmu,USE.NAMES = F) # add the UD product and the integrated covariance term
  cell_foi <- sapply(compsum, "*", beta*lam) # multiply by the epidemiological parameters
  cell_foi <- replace(cell_foi, cell_foi<0, 0)  # substitute negative values for 0s
  return(cell_foi)
}

cell_foi_indep <- calculate_cell_foi(UDprods, cell_cov_int)
```

We obtain a matrix where each column is a combination of two
individuals, and every row is a cell in the landscape. The matrix values
are the estimated FOI experienced by individual 1 from individual 2. By
adding across the columns we can estimate the total FOI for that pair of
individuals. From this matrix we can also calculate the total FOI that
an individual experiences from all other individuals, either at a
specific location or across the whole landscape.

```{r tracks-gg}
sim_tracks_db %>% ggplot()+geom_path(aes(x,y,color = factor(ind)), size=1)+theme_void(base_size = 14)+coord_sf()+labs(color="Individual")+theme(legend.position = "left") -> gg.tracks
```

```{r pairwise-foi}
# total FOI from for every pair of individuals
data.frame(ind_combs, foi = colSums(cell_foi_indep)) |>
  ggplot()+
  geom_raster(aes(factor(ind1),factor(ind2, levels = 6:1),fill=foi))+
  theme_minimal(base_size = 14)+
  labs(fill = "FOI", y = "Acquiring individual", x = "Depositing individual")+
  scale_x_discrete(breaks = 1:6, position = "top",expand = c(0,0))+
  scale_y_discrete(breaks = 1:6, expand = c(0,0))+
  theme(aspect.ratio = 1, panel.grid = element_blank(), axis.ticks = element_line("black")) -> gg.pairfoi
cowplot::plot_grid(gg.tracks,gg.pairfoi)
```

We can see that individual 1 has hardly any overlap, and its FOI values
are the lowest. The product of the UDs is symmetrical, but the
difference in order of arrival at a given site creates small differences
due to the covariance term.

```{r ind-foi}
# total FOI experienced across from all hosts combined
tapply(colSums(cell_foi_indep), ind_combs$ind1, sum)
# total FOI contributed to all other hosts
tapply(colSums(cell_foi_indep), ind_combs$ind2, sum)
```

```{r plot-cellfoi}
# Plot one example
plot(SpatialPixelsDataFrame(coordinates(kuds[[1]]), 
                            data = data.frame(rowSums(cell_foi_indep))))
```

```{r st-dev}
# # We can calculate the sd from the estimated p_i. Can we?
# stdevs_est <- lapply(kuds, \(x) sqrt(as.matrix(x)*(1-as.matrix(x))))

# calculate standard deviation from the data. For a Bernoulli process, the sd is sqrt(p(1-p)), where p is the column mean for the binary location history matrix.
getcellSD <- function(h) sqrt(colMeans(h)*(1-colMeans(h)))
# apply(h, 2, \(x) sqrt(mean(x)*(1-mean(x))))
stdevs <- lapply(loc_histories, getcellSD)
```

```{r}
sapply(cell_covs, rowMeans) %>% as_tibble() %>% add_column(lag = lags) %>% 
  pivot_longer(cols = starts_with("v")) %>% 
  ggplot()+geom_point(aes(lag,value,color = name))
```

#### Joint movement

Now we will do the same for a case where there is joint movement for two
hosts, but the rest are moving independently.

```{r joint-mov}
## 1. Import data, calculate UDs
sim_tracks <- lapply(list.files("../data", "joint(.*).csv",full.names = TRUE), read.csv)
sim_tracks_db <- do.call(rbind, sim_tracks)[,2:3] |> cbind(ind = rep(seq_along(sim_tracks), sapply(sim_tracks,nrow))) 
# create the spatialPoints object with id column
sim_tracks_sppoints <- SpatialPointsDataFrame(coords = sim_tracks_db[,1:2], 
                                              data = data.frame(id = sim_tracks_db$ind))
# get the UDs with a common grid
kuds <- kernelUD(sim_tracks_sppoints, same4all = TRUE)
# Get the cell area, for FOI calculation
cell_area <- kuds[[1]]@grid@cellsize |> prod()

## 2. UD product
ind_combs <- expand.grid(ind2 = seq_along(kuds), ind1 = seq_along(kuds))
ind_combs <- ind_combs[ind_combs$ind1!=ind_combs$ind2,]
UDprods <- apply(ind_combs, 1, \(x) udprod(kuds[[x[2]]],kuds[[x[1]]]), simplify = FALSE)

## 3. Location history
# Get the distance between the grid cell centers and every point in the tracking history. 
point_grid_dists <- spDists(sim_tracks_sppoints, kuds[[1]])
# Create a binary matrix and split it by individual
loc_histories <-  apply(point_grid_dists, MARGIN = 1, \(x) x==min(x)) |> t() |>
  split(factor(sim_tracks_db$ind)) |> 
  lapply(matrix, ncol = ncol(point_grid_dists))

## 4. Get the covariance
cell_covs_joint <- get_cov(loc_histories)

## 5. multiply by the decay, and sum across to integrate
cell_cov_int <- lapply(cell_covs_joint, "*", exp(-nu*lags)) |> lapply(colSums)

## 6. Combine the integrated covariance term and the  UD product, and scale by the epi parameters
cell_foi_joint <- calculate_cell_foi(UDprods, cell_cov_int)
```

```{r plot_joint_sim}
## 7. plots
data.frame(ind_combs, foi = colSums(cell_foi_joint))|>
  ggplot()+
  geom_raster(aes(factor(ind1),factor(ind2, levels = 6:1),fill=foi))+
  theme_minimal(base_size = 14)+
  labs(fill = "FOI", y = "Acquiring individual", x = "Depositing individual")+
  scale_x_discrete(breaks = 1:6, position = "top",expand = c(0,0))+
  scale_y_discrete(breaks = 1:6, expand = c(0,0))+
  theme(aspect.ratio = 1, panel.grid = element_blank()) -> gg.pairfoi

data.frame(ind_combs, foi = beta*lam*sapply(UDprods, sum)) |>
  ggplot()+
  geom_raster(aes(factor(ind1),factor(ind2, levels = 6:1),fill=foi))+
  theme_minimal(base_size = 14)+
  labs(fill = "FOI", y = "Acquiring individual", x = "Depositing individual")+
  scale_x_discrete(breaks = 1:6, position = "top",expand = c(0,0))+
  scale_y_discrete(breaks = 1:6, expand = c(0,0))+
  theme(aspect.ratio = 1, panel.grid = element_blank())-> gg.pairfoiindep

gg.tracks <- sim_tracks_db %>% ggplot()+geom_path(aes(x,y,color = factor(ind)), size=1)+theme_void(base_size = 14)+coord_sf()+labs(color="Individual")+theme(legend.position = "left")

plot_grid(gg.tracks,plot_grid(gg.pairfoi,gg.pairfoiindep,nrow=2, align = "v"))
```

There is a clear difference in FOI between the two individuals who are
moving together, and the rest. The estimated FOI is at least twice as
high for that pair as for the others. This difference is not due solely
to the degree of overlap; while they do have the highest degree of
overlap, they also overlap similarly with other individuals,

What happens if we do not incorporate the covariance term? This is, what
if we assumed independent movement, and only used the product of the
UDs, how much error would we be incurring?

```{r, fig.height=3}
tibble(ind_combs, foi_full = colSums(cell_foi_joint), foi_ud = beta*lam*sapply(UDprods,sum)) %>% mutate(udprop = (foi_full-foi_ud)/foi_full) %>% 
  ggplot()+geom_raster(aes(ind1,ind2, fill = udprop))+
  # scale_fill_gradient2(midpoint = 1)+
  theme_minimal()+
  theme(aspect.ratio = 1, panel.grid = element_blank())+
  labs(x = "Depositing individual", y = "Acquiring individual", fill = "Cov contribution")
```

In cases where there is little overlap the product of the UDs makes up
the majority of the FOI. However when the individual tracks do overlap,
the covariance term seemingly makes up the majority of the FOI.

Let's see how the covariance varies for the different combinations of
individuals.

```{r}
# First let's see how the covariance term changes in response to s, the lag
sapply(cell_covs_joint, rowMeans) %>% as_tibble() %>% add_column(lag = lags) %>% 
  pivot_longer(cols = starts_with("v")) %>% 
  ggplot()+geom_point(aes(lag,value,color = name))+
  theme_classic(base_size = 14)+
  labs(x = "Lag s", y = "Covariance")
```

We see there is some periodic behavior with respect to the lag $s$ for a
couple of the covariance series, the two combinations of the individuals
that are moving together. The covariance is positive and high for small
lags but decreases sharply. For the other series---with independent
movement---there is no clear trend.

Let's take a look at the covariance term and how it's related to
overlap.

```{r}
m1 <- kerneloverlap(sim_tracks_sppoints)
m2 <- diag(6)
m2[as.numeric(rownames(ind_combs))] <- sapply(cell_cov_int, sum)
plot(m1,m2)
```

```{r}
sapply(cell_covs_joint, rowMeans) %>% as_tibble() %>% add_column(lag = lags) %>% 
  pivot_longer(cols = starts_with("v")) %>% 
  ggplot()+geom_boxplot(aes(name,value))+
  theme_classic(base_size = 14)+
  labs(x = "Pair", y = "Covariance")
```

```{r}

```

## Upper left-hand corner -- uniform space use

There are instances in which we will not have spatially explicit data.
The most evident case is that of proximity loggers, for which you can
know *when* and *for how long* two individuals were in contact with each
other, but you have no information about where that contact occurred, or
whether the location was constant--which will matter for indirect
contact. For these cases we need to adapt the general framework so that
space use can be implicit. One option is to assume a uniform probability
of spatial use. In this case we use a slightly different format for the
general equation. We don't break it into the covariance and the
probability of use, but instead write it in terms of conditional
probability as follows:

$$
\begin{align}
E[h_{i \leftarrow j}(x, t)] &= \beta \lambda \left[\int_{-\infty}^t E[\delta_i(x, t) \delta_j(x, u)] e^{-\nu(t - u)} du\right] \\
&= \beta \lambda \left[ \int_{-\infty}^t P(i \in x \text{ at }t|j \in x \text{ at } u) P(j \in x \text{ at } u) e^{-\nu (t-u)}du\right]
\end{align}
$$

Here, $P(i \in x \text{ at } t | j \in x \text{ at } u)$ is the
probability that host $i$ is in $x$ at time $t$, given host $j$ was in
$x$ at a previous time $u$. Since we are assuming uniform space use, the
probability of being at any given location $x$ is equal across space, so
$P(j \in x \text{ at } u) = P(j\in x) = 1/A_{j,tot}$, where $A_{j,tot}$
is the total area used by $j$. We have then

$$
\begin{align}
E[h_{i \leftarrow j}(x, t)] &= \beta \lambda \left[ \int_{-\infty}^t P(i \in x \text{ at }t|j \in x \text{ at } u) \frac{1}{A_{j,tot}} e^{-\nu (t-u)}du\right]\\
&=\frac{\beta\lambda}{A_{j,tot}}\int_{-\infty}^t P(i \in x \text{ at }t|j \in x \text { at } u) e^{-\nu(t-u)}du
\end{align}
$$

We can also take $x$ to represent an area of influence, rather than a
single point in space. In that case we scale the transmission term by
the area of $x$, and obtain $$
E[h_{i \leftarrow j}(x, t)] = \frac{\beta'\lambda}{A_x}\frac{A_x}{A_{j,tot}}\int_{-\infty}^t P(i \in x \text{ at } t | j \in x \text{ at } u)  e^{-\nu(t - u)} du
$$

The key here is that, because we are assuming space is uniform (or we
just don't have information on space use so we are defaulting to an
equal probability assumption), any location $x$ with area $A_x$ is just
like any other location with area $A_x$. So the location $x$ doesn't
matter, just the area $A_x$. The area $A_x$ can be defined specifically
as the area around an individual within which a contact can occur.
$P(j \in x \text{ at } u) = \frac{A_x}{A_{j, tot}}$ because it again
doesn't matter what $x$ host $j$ is in because given uniform space use,
your probability of being in any area $A_x$ is just $A_x$ over the total
area of use. The conditional probability would theoretically capture any
potential correlation between visits of $i$ and $j$, potentially linked
with attraction or avoidance behaviors.

------------------------------------------------------------------------

***Special case: independent movement***

If there is no correlation (i.e. $i$ and $j$ move independently from
each other), the probabilities are also independent, so
$P(i\in x \text{ at }t | j \in x \text{ at } u)=P(i\in x \text{ at }t)=A_x/A_{i,tot}$,
therefore we would have

$$
\begin{align}
E[h_{i \leftarrow j}(x, t)] &= \frac{\beta'}{A_x}\frac{A_x}{A_{j,tot}} \lambda \int_{-\infty}^t  \frac{A_x}{A_{i,tot}} e^{-\nu(t - u)} du \\
&=\frac{\beta'\lambda}{A_x} \frac{(A_x)^2}{A_{i,tot}A_{j,tot}}\int_{-\infty}^t   e^{-\nu(t - u)} du\\
&=\frac{\beta'\lambda}{\nu}  \frac{A_x}{A_{i,tot}A_{j,tot}}
\end{align}
$$

This is, the expected FOI from $j$ to $i$, assuming uniform space use
and independently moving individuals, is proportional to the ratio of
the area of overlap and the product of the two areas of use. In this
special case, since the area of overlap is the same, this FOI is
symmetrical. This is the same result as the home range overlap metric.

------------------------------------------------------------------------

### Estimating from data

1.  If movement is not independent, we need to determine the conditional
    probability $P(i \in x \text{ at }t|j \in x \text{ at }u)$. In the
    special case of only direct contact, $t=u$, this is simply the
    probability of $i$ and $j$ being at the same location at the same
    time. What this gives is a contact vector of 0s and 1s through time,
    exactly the type of data we would get from proximity loggers.
2.  Knowing the lagged versions of
    $P(i \in x \text{ at } t | j \in x \text{ at } u)$ is impossible
    from just proximity logger data, but we could start inferring that
    if we had stationary environmental loggers, or with camera-traps. In
    this case, you can know the exact time lag between individuals
    coming to a common location. The cool thing is, then all we have to
    do is use a logistic regression with a time-varying spline (or
    something similar) to estimate how contact probability varies
    through time.
3.  We also need $A_{j, tot}$ for one of the hosts. Alternatively, you
    could just redefine
    $\beta = \frac{\beta'}{A_{j, tot}} = \frac{\beta'}{A_x} \frac{A_x}{A_{j, tot}}$

```{r, fig.cap="Distribution of waiting times for appearance of i at a given location x following the appearance of j at a previous time - Independent movement"}
#' Create a detection history for two individuals at a stationary logger. 
#' Both appear at constant rates lambda_i = 1/2 and lambda_j = 1/3
lami = 1/2
lamj = 1/3
# The inter-event waiting times are given by the exponential distribution
lag_i = rexp(20, rate = lami)
lag_j = rexp(20, rate = lamj)

# get absolute times
timesi = cumsum(lag_i)
timesj = cumsum(lag_j)

# get the lag between i and j
lags_ij <- outer(timesi, timesj, "-")

# get the minimum positive lag (i.e. the time since the most recent j) for every i
minlag <- apply(lags_ij, 1, \(x) min(x[x>0])) 
lag_dens <- density(minlag, from = 0)
hist(minlag, freq = F,xlab = "Time lag s", main = "", ylab = "Probability")
lines(lag_dens$x, lag_dens$y, col="red")
```

```{r}
with(
  data.frame(beta = 1, lam = 1, mu = 1,
             Ax = 1, Ai = 2, Aj = 3),
  cat("Estimated FOI =", beta*lam/Aj*sum(lag_dens$y*exp(-1*lag_dens$x)))
)
```

------------------------------------------------------------------------

***NOTE: THIS NEEDS CHECKING***

For indirect contact ($t \gt u$), the conditional probability can be
interpreted as the probability that $i$ arrives in $x$ ($t-u$) time
units after $j$. Put differently, it is the probability that $j$ was in
$x$ at a certain time point, and then elsewhere for ($t-u$), and that
$i$ was not in $x$ from $u$ to $t$ but arrived there at time $t$. The
specific time points $t$ and $u$ are not important, rather it's the lag
$s$ that we care about. Assuming uniform space use, we define:

-   $P(i \in x \text{ at }t)=1/A_{i,tot}$ The probability that any
    individual $i$ is at any given location $x$ at a certain point in
    time

-   $P(i \notin x \text{ at }t)=1-1/A_{i,tot}$ The probability that $i$
    is anywhere but $x$ at a certain point in time

**Mark here**: I think we are getting different answers here because
your verbal interpretation of
$P(i \in x \text{ at } t | j \in x \text{ at } u)$ is different than
mine. I would verbally interpret
$P(i \in x \text{ at } t | j \in x \text{ at } u)$ as instantaneous
where you are interpreting it (I think) as cumulative. For example, you
state that $P(i \in x \text{ at } t | j \in x \text{ at } u)$ also tells
us where $j$ wasn't for $t - u$. My interpretation that it doesn't tell
us anything about where $j$ wasn't. $j$ could have been in $x$ for part
of $t - u$ or all of $t - u$. I would argue we don't know that from
$P(i \in x \text{ at } t | j \in x \text{ at } u)$ -- we just know given
$j$ was there at past time $u$, is $i$ there right now? We could start
multiplying these $P(i \in x \text{ at } t | j \in x \text{ at } u)$
together over different lags to ask for the probability that $i$ is in
$x$ for some time period $t + \delta t$ but not in $x$ for the time
period $t - u$, but I don't think
$P(i \in x \text{ at } t | j \in x \text{ at } u)$ alone can tell us
that.

Then we have

$$
\begin{align}
P(i \in x \text{ at }t|j \in x \text{ at } t-s)&=\frac{1}{A_{i,tot}}\left(1-\frac{1}{A_{i,tot}}\right)^s\frac{1}{A_{j,tot}}\left(1-\frac{1}{A_{j,tot}}\right)^s\\
&=\frac{1}{A_{i,tot}A_{j,tot}} \left[\left(1-\frac{1}{A_{i,tot}}\right)\left( 1-\frac{1}{A_{j,tot}}\right)\right]^s\\
\end{align}
$$

If again we focus on areas, we have

$$
\begin{align}
P(i \in x \text{ at }t|j \in x \text{ at } t-s)&=\frac{A_x^2}{A_{i,tot}A_{j,tot}} \left[\left(1-\frac{A_x}{A_{i,tot}}\right)\left( 1-\frac{A_x}{A_{j,tot}}\right)\right]^s\\
\end{align}
$$

This is, the conditional probability that $i$ comes to $x$, $s$ time
units after $j$, is the square of the area $A_x$ ---where contact can
occur---divided by the product of both total areas, multiplied by the
product of the areas of use excluding area $x$ elevated to the time lag.

Integrating we obtain

$$
\begin{align}
E[h_{i \leftarrow j}(x,t)]&=\frac{\beta'\lambda}{A_x}\frac{A_x}{A_j}\int_0^\infty \frac{A_x^2}{A_iA_j} \left[\left(1-\frac{A_x}{A_i} \right) \left(1-\frac{A_x}{A_j} \right)\right]^s e^{-\nu s}ds\\
&=\frac{\beta'\lambda}{A_x}\frac{A_x}{A_j} \frac{A_x^2}{A_iA_j} \int_0^\infty \left[\left(1-\frac{A_x}{A_i} \right) \left(1-\frac{A_x}{A_j} \right)\right]^s e^{-\nu s}ds\\
&=C\int_0^\infty (Fe^{-\nu})^sds
\end{align}
$$

where $C=\frac{\beta'\lambda A_x^2}{A_iA_j^2}$ and
$F=\left[\left(1-\frac{A_x}{A_i} \right) \left(1-\frac{A_x}{A_j} \right)\right]$.
The integral is of the form $\int a^u du = a^u/\ln(a)$, so

$$
\begin{align}
C\int_0^\infty(Fe^{-\nu})^sds&=C\frac{(Fe^{-\nu})^s}{\ln(Fe^{-\nu})}\\
&=C\frac{(Fe^{-\nu})^s}{\ln(F)-\nu}
\end{align}
$$

$0<F<1$ and $0<e^{-\nu}<1$, so evaluating we obtain

$$
\begin{align}
\frac{C}{\ln(F)-\nu} (Fe^{-\nu})^s|_0^\infty &=\frac{C}{\ln(F)-\nu}(-1)\\
&=\frac{C}{\nu-\ln(F)}
\end{align}
$$

Replacing $C$ and $F$ gives

$$
E[h_{i\leftarrow j}(x,t)]=\frac{\beta'\lambda A_x^2}{A_iA_j^2}\frac{1}{\nu-\ln\left[\left(1-\frac{A_x}{A_i}\right)\left(1-\frac{A_x}{A_j}\right)\right]}
$$

Is this just the same as the special case described above for
independent movement,
$E[h_{i \leftarrow j}(x,t)]=\frac{\beta'\lambda}{\nu} \frac{A_x}{A_{i,tot}A_{j,tot}}$?

Let's look at an example. Say we have two individuals with $A_i=2$ and
$A_j=3$, and the area of overlap is $A_x=1$.

```{r, echo = FALSE, fig.cap="Conditional probability of the time lag between two individuals i and j at the same location x"}
with(
  data.frame(
    Ax=1,Ai=2,Aj=3
  ),
  # plot the conditional probability for different time lags
  curve(Ax^2/(Ai*Aj)*((1-Ax/Ai)*(1-Ax/Aj))^x,from = 0,to = 10,
      xlab = "Time lag s", ylab = "Conditional probability")
)
```

The conditional probability depends only on the areas of use and of
overlap. This probability of $i$ appearing at $x$ decreases
exponentially as the time lag following the appearance of $j$ increases.
Assuming $\beta=\lambda=\nu=1$, we have

```{r}
b=1
nu=1
lam=1
Ax=1
Ai=2
Aj=3
Eh1 = b*lam/nu*Ax/(Ai*Aj)
Eh2 = b*lam*Ax^2/(Ai*Aj^2)*1/(nu-log((1-Ax/Ai)*(1-Ax/Aj)))
cat("FOI indep. mov =",Eh1,"\nFOI derived =",Eh2)
```

<!--# I'm not sure this difference is real or just some miscalculation -->

## Lower left-hand corner

The general equation for the lower left-hand corner is

$$
\begin{align}
E[h_{i \leftarrow j}(x, t)] &= \frac{\beta'}{A_x} \lambda \left[\int_{-\infty}^t E[\delta_i(x, t) \delta_j(x, u)] e^{-\nu(t - u)} du\right] \\
&= \frac{\beta'}{A_x} \lambda \left[\int_{0}^{\infty} P(i \in x | j \in x, s) \frac{A_x}{A_{j, tot}} e^{-\nu(s)} ds\right]
\end{align}
$$

-   $P(i \in x | j \in x, s)$: The probability of host $i$ in some
    location $x$ with area $A_x$ given host $j$ in some location $x$
    given a time lag of $s$.

This is similar to the upper left-hand corner, but now time is
stationary so we just have one mean contact probability (independent of
time) for each lag $s$.

### Estimating from data

-   To estimate $P(i \in x | j \in x, s)$ for lag $s = 0$, you just need
    a vector of 0 or 1 contacts between host $i$ and $j$ and calculate
    the probability of contact.
